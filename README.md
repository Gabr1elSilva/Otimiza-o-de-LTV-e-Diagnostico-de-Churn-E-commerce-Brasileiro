# Perguntar

## Cen√°rio

A Olist opera como um ecossistema vital no varejo brasileiro, conectando milhares de pequenos vendedores a grandes marketplaces. No entanto, diferentemente de um servi√ßo de assinatura (como a Netflix ou Spotify) onde o cliente liga para cancelar o contrato, no e-commerce o fim do relacionamento √© silencioso. O cliente n√£o avisa que vai embora; ele simplesmente para de comprar.

Estamos diante de um cen√°rio de Churn N√£o Contratual. A empresa pode estar celebrando recordes de aquisi√ß√£o de novos clientes, sem perceber que est√° sofrendo de um efeito "balde furado" (leaky bucket): a base de clientes antigos est√° se degradando silenciosamente. Se a maioria dos clientes realiza apenas uma compra e nunca mais retorna, o Custo de Aquisi√ß√£o de Cliente (CAC) corr√≥i a margem de lucro, tornando o crescimento insustent√°vel a longo prazo. O desafio n√£o √© apenas vender mais, mas entender quem parou de comprar e, crucialmente, por qu√™.

## Quest√µes para an√°lise

Para estancar essa sangria de receita, precisamos ir al√©m de m√©tricas superficiais e responder perguntas diagn√≥sticas:
* **A Defini√ß√£o do Abandono:** Em um cen√°rio sem cancelamento formal, qual √© a "janela de inatividade" exata que define um cliente como perdido? N√£o podemos usar um n√∫mero arbitr√°rio (ex: 30 dias); precisamos que os dados nos digam quando a probabilidade de retorno cai drasticamente.
* **Diagn√≥stico de Causa Raiz:** O churn √© um problema de produto ou de opera√ß√£o? Existe uma correla√ß√£o direta entre atrasos log√≠sticos (atraso na entrega) e a decis√£o do cliente de n√£o recomprar?.
* **Qualidade da Safra:** A reten√ß√£o est√° piorando ao longo do tempo? As novas safras de clientes (adquiridos, por exemplo, na Black Friday) s√£o menos leais do que as safras antigas?.
* **Impacto Financeiro:** Estamos perdendo clientes de alto valor ou apenas "turistas" de promo√ß√µes? Quem s√£o as "baleias" (clientes VIP) que est√£o em risco de churn e que justificariam uma campanha de reten√ß√£o cara?.

## Tarefa de Neg√≥cios

Minha miss√£o n√£o √© apenas construir um modelo que preveja se um cliente vai sair, mas desenvolver uma An√°lise Diagn√≥stica de Reten√ß√£o que explique os motivos econ√¥micos e comportamentais por tr√°s da evas√£o.

A tarefa consiste em:
1. **Engenharia de Defini√ß√£o:** Criar uma l√≥gica robusta para classificar clientes em "Ativos", "Em Risco" e "Churn", baseada em seus intervalos hist√≥ricos de compra.
2. **Identifica√ß√£o de Atritos:** Quantificar quanto dinheiro a empresa perde devido a falhas operacionais.
3. **Segmenta√ß√£o Acion√°vel:** Utilizar a an√°lise RFM (Rec√™ncia, Frequ√™ncia, Valor) para entregar √† equipe de marketing uma lista priorizada de clientes de alto valor que est√£o adormecendo, permitindo a√ß√µes de reativa√ß√£o antes que seja tarde demais.

## Defini√ß√£o de Sucesso

O sucesso deste projeto ser√° medido pela acionabilidade dos insights gerados para a tomada de decis√£o. Consideraremos o projeto bem-sucedido se conseguirmos:
* Demonstrar visualmente a din√¢mica de perda de clientes atrav√©s de fluxos ou An√°lises de Coorte, tornando o problema evidente para stakeholders n√£o t√©cnicos.
* Prover recomenda√ß√µes estrat√©gicas claras que tenham potencial te√≥rico de aumentar o Lifetime Value (LTV) da base de clientes.

# Preparar

Antes de qualquer an√°lise, √© importante realizar uma explora√ß√£o rigorosa na integridade dos dados. Nesta etapa, atuamos como "detetives de dados", buscando inconsist√™ncias estruturais, tipagens incorretas e anomalias estat√≠sticas que poderiam enviesar nossa defini√ß√£o de Churn.

## Configura√ß√£o do Ambiente e Ingest√£o

O ecossistema de dados da Olist √© distribu√≠do em m√∫ltiplas tabelas relacionais. Para consolidar a vis√£o do cliente, utilizaremos pandas para manipula√ß√£o alg√©brica e seaborn/matplotlib para diagn√≥sticos visuais.


```python
pip install unidecode
```

    Collecting unidecode
      Downloading Unidecode-1.4.0-py3-none-any.whl.metadata (13 kB)
    Downloading Unidecode-1.4.0-py3-none-any.whl (235 kB)
    [2K   [90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ[0m [32m235.8/235.8 kB[0m [31m6.3 MB/s[0m eta [36m0:00:00[0m
    [?25hInstalling collected packages: unidecode
    Successfully installed unidecode-1.4.0
    Note: you may need to restart the kernel to use updated packages.
    


```python
# Manipula√ß√£o e Engenharia de Dados
import numpy as np 
import pandas as pd 
from datetime import datetime
import math
import re
import plotly.express as px
from wordcloud import WordCloud
from collections import Counter
import matplotlib.ticker as mtick
from matplotlib.ticker import FuncFormatter
import matplotlib.dates as mdates
import unidecode

# Visualiza√ß√£o
import plotly.express as px
import plotly.graph_objects as go
import seaborn as sns
import matplotlib.pyplot as plt
import matplotlib.patheffects as path_effects

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# Configura√ß√µes de Visualiza√ß√£o
import warnings
warnings.filterwarnings('ignore') 
pd.set_option('display.float_format', lambda x: '%.2f' % x)
```

    /kaggle/input/brazilian-ecommerce/olist_customers_dataset.csv
    /kaggle/input/brazilian-ecommerce/olist_sellers_dataset.csv
    /kaggle/input/brazilian-ecommerce/olist_order_reviews_dataset.csv
    /kaggle/input/brazilian-ecommerce/olist_order_items_dataset.csv
    /kaggle/input/brazilian-ecommerce/olist_products_dataset.csv
    /kaggle/input/brazilian-ecommerce/olist_geolocation_dataset.csv
    /kaggle/input/brazilian-ecommerce/product_category_name_translation.csv
    /kaggle/input/brazilian-ecommerce/olist_orders_dataset.csv
    /kaggle/input/brazilian-ecommerce/olist_order_payments_dataset.csv
    

## Carregamento dos datasets


```python
customers = pd.read_csv('/kaggle/input/brazilian-ecommerce/olist_customers_dataset.csv')
geolocation = pd.read_csv('/kaggle/input/brazilian-ecommerce/olist_geolocation_dataset.csv')
order_items = pd.read_csv('/kaggle/input/brazilian-ecommerce/olist_order_items_dataset.csv')
order_payments = pd.read_csv('/kaggle/input/brazilian-ecommerce/olist_order_payments_dataset.csv')
order_reviews = pd.read_csv('/kaggle/input/brazilian-ecommerce/olist_order_reviews_dataset.csv')
orders = pd.read_csv('/kaggle/input/brazilian-ecommerce/olist_orders_dataset.csv')
products = pd.read_csv('/kaggle/input/brazilian-ecommerce/olist_products_dataset.csv')
sellers = pd.read_csv('/kaggle/input/brazilian-ecommerce/olist_sellers_dataset.csv')
```

## Auditoria Dimensional e Amostral

Precisamos dimensionar o volume de informa√ß√µes dispon√≠veis. A volumetria dita se precisamos de t√©cnicas de Big Data ou se o processamento em mem√≥ria √© suficiente.


```python
customers.shape
```




    (99441, 5)




```python
geolocation.shape
```




    (1000163, 5)




```python
order_items.shape
```




    (112650, 7)




```python
order_payments.shape
```




    (103886, 5)




```python
order_reviews.shape
```




    (99224, 7)




```python
orders.shape
```




    (99441, 8)




```python
products.shape
```




    (32951, 9)




```python
sellers.shape
```




    (3095, 4)




```python
customers.columns
```




    Index(['customer_id', 'customer_unique_id', 'customer_zip_code_prefix',
           'customer_city', 'customer_state'],
          dtype='object')




```python
geolocation.columns
```




    Index(['geolocation_zip_code_prefix', 'geolocation_lat', 'geolocation_lng',
           'geolocation_city', 'geolocation_state'],
          dtype='object')




```python
order_items.columns
```




    Index(['order_id', 'order_item_id', 'product_id', 'seller_id',
           'shipping_limit_date', 'price', 'freight_value'],
          dtype='object')




```python
order_payments.columns
```




    Index(['order_id', 'payment_sequential', 'payment_type',
           'payment_installments', 'payment_value'],
          dtype='object')




```python
order_reviews.columns
```




    Index(['review_id', 'order_id', 'review_score', 'review_comment_title',
           'review_comment_message', 'review_creation_date',
           'review_answer_timestamp'],
          dtype='object')




```python
orders.columns
```




    Index(['order_id', 'customer_id', 'order_status', 'order_purchase_timestamp',
           'order_approved_at', 'order_delivered_carrier_date',
           'order_delivered_customer_date', 'order_estimated_delivery_date'],
          dtype='object')




```python
products.columns
```




    Index(['product_id', 'product_category_name', 'product_name_lenght',
           'product_description_lenght', 'product_photos_qty', 'product_weight_g',
           'product_length_cm', 'product_height_cm', 'product_width_cm'],
          dtype='object')




```python
sellers.columns
```




    Index(['seller_id', 'seller_zip_code_prefix', 'seller_city', 'seller_state'], dtype='object')




```python
customers.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>customer_id</th>
      <th>customer_unique_id</th>
      <th>customer_zip_code_prefix</th>
      <th>customer_city</th>
      <th>customer_state</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>06b8999e2fba1a1fbc88172c00ba8bc7</td>
      <td>861eff4711a542e4b93843c6dd7febb0</td>
      <td>14409</td>
      <td>franca</td>
      <td>SP</td>
    </tr>
    <tr>
      <th>1</th>
      <td>18955e83d337fd6b2def6b18a428ac77</td>
      <td>290c77bc529b7ac935b93aa66c333dc3</td>
      <td>9790</td>
      <td>sao bernardo do campo</td>
      <td>SP</td>
    </tr>
    <tr>
      <th>2</th>
      <td>4e7b3e00288586ebd08712fdd0374a03</td>
      <td>060e732b5b29e8181a18229c7b0b2b5e</td>
      <td>1151</td>
      <td>sao paulo</td>
      <td>SP</td>
    </tr>
    <tr>
      <th>3</th>
      <td>b2b6027bc5c5109e529d4dc6358b12c3</td>
      <td>259dac757896d24d7702b9acbbff3f3c</td>
      <td>8775</td>
      <td>mogi das cruzes</td>
      <td>SP</td>
    </tr>
    <tr>
      <th>4</th>
      <td>4f2d8ab171c80ec8364f7c12e35b23ad</td>
      <td>345ecd01c38d18a9036ed96c73b8d066</td>
      <td>13056</td>
      <td>campinas</td>
      <td>SP</td>
    </tr>
  </tbody>
</table>
</div>




```python
geolocation.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>geolocation_zip_code_prefix</th>
      <th>geolocation_lat</th>
      <th>geolocation_lng</th>
      <th>geolocation_city</th>
      <th>geolocation_state</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1037</td>
      <td>-23.55</td>
      <td>-46.64</td>
      <td>sao paulo</td>
      <td>SP</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1046</td>
      <td>-23.55</td>
      <td>-46.64</td>
      <td>sao paulo</td>
      <td>SP</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1046</td>
      <td>-23.55</td>
      <td>-46.64</td>
      <td>sao paulo</td>
      <td>SP</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1041</td>
      <td>-23.54</td>
      <td>-46.64</td>
      <td>sao paulo</td>
      <td>SP</td>
    </tr>
    <tr>
      <th>4</th>
      <td>1035</td>
      <td>-23.54</td>
      <td>-46.64</td>
      <td>sao paulo</td>
      <td>SP</td>
    </tr>
  </tbody>
</table>
</div>




```python
order_items.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>order_id</th>
      <th>order_item_id</th>
      <th>product_id</th>
      <th>seller_id</th>
      <th>shipping_limit_date</th>
      <th>price</th>
      <th>freight_value</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>00010242fe8c5a6d1ba2dd792cb16214</td>
      <td>1</td>
      <td>4244733e06e7ecb4970a6e2683c13e61</td>
      <td>48436dade18ac8b2bce089ec2a041202</td>
      <td>2017-09-19 09:45:35</td>
      <td>58.90</td>
      <td>13.29</td>
    </tr>
    <tr>
      <th>1</th>
      <td>00018f77f2f0320c557190d7a144bdd3</td>
      <td>1</td>
      <td>e5f2d52b802189ee658865ca93d83a8f</td>
      <td>dd7ddc04e1b6c2c614352b383efe2d36</td>
      <td>2017-05-03 11:05:13</td>
      <td>239.90</td>
      <td>19.93</td>
    </tr>
    <tr>
      <th>2</th>
      <td>000229ec398224ef6ca0657da4fc703e</td>
      <td>1</td>
      <td>c777355d18b72b67abbeef9df44fd0fd</td>
      <td>5b51032eddd242adc84c38acab88f23d</td>
      <td>2018-01-18 14:48:30</td>
      <td>199.00</td>
      <td>17.87</td>
    </tr>
    <tr>
      <th>3</th>
      <td>00024acbcdf0a6daa1e931b038114c75</td>
      <td>1</td>
      <td>7634da152a4610f1595efa32f14722fc</td>
      <td>9d7a1d34a5052409006425275ba1c2b4</td>
      <td>2018-08-15 10:10:18</td>
      <td>12.99</td>
      <td>12.79</td>
    </tr>
    <tr>
      <th>4</th>
      <td>00042b26cf59d7ce69dfabb4e55b4fd9</td>
      <td>1</td>
      <td>ac6c3623068f30de03045865e4e10089</td>
      <td>df560393f3a51e74553ab94004ba5c87</td>
      <td>2017-02-13 13:57:51</td>
      <td>199.90</td>
      <td>18.14</td>
    </tr>
  </tbody>
</table>
</div>




```python
order_payments.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>order_id</th>
      <th>payment_sequential</th>
      <th>payment_type</th>
      <th>payment_installments</th>
      <th>payment_value</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>b81ef226f3fe1789b1e8b2acac839d17</td>
      <td>1</td>
      <td>credit_card</td>
      <td>8</td>
      <td>99.33</td>
    </tr>
    <tr>
      <th>1</th>
      <td>a9810da82917af2d9aefd1278f1dcfa0</td>
      <td>1</td>
      <td>credit_card</td>
      <td>1</td>
      <td>24.39</td>
    </tr>
    <tr>
      <th>2</th>
      <td>25e8ea4e93396b6fa0d3dd708e76c1bd</td>
      <td>1</td>
      <td>credit_card</td>
      <td>1</td>
      <td>65.71</td>
    </tr>
    <tr>
      <th>3</th>
      <td>ba78997921bbcdc1373bb41e913ab953</td>
      <td>1</td>
      <td>credit_card</td>
      <td>8</td>
      <td>107.78</td>
    </tr>
    <tr>
      <th>4</th>
      <td>42fdf880ba16b47b59251dd489d4441a</td>
      <td>1</td>
      <td>credit_card</td>
      <td>2</td>
      <td>128.45</td>
    </tr>
  </tbody>
</table>
</div>




```python
order_reviews.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>review_id</th>
      <th>order_id</th>
      <th>review_score</th>
      <th>review_comment_title</th>
      <th>review_comment_message</th>
      <th>review_creation_date</th>
      <th>review_answer_timestamp</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>7bc2406110b926393aa56f80a40eba40</td>
      <td>73fc7af87114b39712e6da79b0a377eb</td>
      <td>4</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>2018-01-18 00:00:00</td>
      <td>2018-01-18 21:46:59</td>
    </tr>
    <tr>
      <th>1</th>
      <td>80e641a11e56f04c1ad469d5645fdfde</td>
      <td>a548910a1c6147796b98fdf73dbeba33</td>
      <td>5</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>2018-03-10 00:00:00</td>
      <td>2018-03-11 03:05:13</td>
    </tr>
    <tr>
      <th>2</th>
      <td>228ce5500dc1d8e020d8d1322874b6f0</td>
      <td>f9e4b658b201a9f2ecdecbb34bed034b</td>
      <td>5</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>2018-02-17 00:00:00</td>
      <td>2018-02-18 14:36:24</td>
    </tr>
    <tr>
      <th>3</th>
      <td>e64fb393e7b32834bb789ff8bb30750e</td>
      <td>658677c97b385a9be170737859d3511b</td>
      <td>5</td>
      <td>NaN</td>
      <td>Recebi bem antes do prazo estipulado.</td>
      <td>2017-04-21 00:00:00</td>
      <td>2017-04-21 22:02:06</td>
    </tr>
    <tr>
      <th>4</th>
      <td>f7c4243c7fe1938f181bec41a392bdeb</td>
      <td>8e6bfb81e283fa7e4f11123a3fb894f1</td>
      <td>5</td>
      <td>NaN</td>
      <td>Parab√©ns lojas lannister adorei comprar pela I...</td>
      <td>2018-03-01 00:00:00</td>
      <td>2018-03-02 10:26:53</td>
    </tr>
  </tbody>
</table>
</div>




```python
orders.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>order_id</th>
      <th>customer_id</th>
      <th>order_status</th>
      <th>order_purchase_timestamp</th>
      <th>order_approved_at</th>
      <th>order_delivered_carrier_date</th>
      <th>order_delivered_customer_date</th>
      <th>order_estimated_delivery_date</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>e481f51cbdc54678b7cc49136f2d6af7</td>
      <td>9ef432eb6251297304e76186b10a928d</td>
      <td>delivered</td>
      <td>2017-10-02 10:56:33</td>
      <td>2017-10-02 11:07:15</td>
      <td>2017-10-04 19:55:00</td>
      <td>2017-10-10 21:25:13</td>
      <td>2017-10-18 00:00:00</td>
    </tr>
    <tr>
      <th>1</th>
      <td>53cdb2fc8bc7dce0b6741e2150273451</td>
      <td>b0830fb4747a6c6d20dea0b8c802d7ef</td>
      <td>delivered</td>
      <td>2018-07-24 20:41:37</td>
      <td>2018-07-26 03:24:27</td>
      <td>2018-07-26 14:31:00</td>
      <td>2018-08-07 15:27:45</td>
      <td>2018-08-13 00:00:00</td>
    </tr>
    <tr>
      <th>2</th>
      <td>47770eb9100c2d0c44946d9cf07ec65d</td>
      <td>41ce2a54c0b03bf3443c3d931a367089</td>
      <td>delivered</td>
      <td>2018-08-08 08:38:49</td>
      <td>2018-08-08 08:55:23</td>
      <td>2018-08-08 13:50:00</td>
      <td>2018-08-17 18:06:29</td>
      <td>2018-09-04 00:00:00</td>
    </tr>
    <tr>
      <th>3</th>
      <td>949d5b44dbf5de918fe9c16f97b45f8a</td>
      <td>f88197465ea7920adcdbec7375364d82</td>
      <td>delivered</td>
      <td>2017-11-18 19:28:06</td>
      <td>2017-11-18 19:45:59</td>
      <td>2017-11-22 13:39:59</td>
      <td>2017-12-02 00:28:42</td>
      <td>2017-12-15 00:00:00</td>
    </tr>
    <tr>
      <th>4</th>
      <td>ad21c59c0840e6cb83a9ceb5573f8159</td>
      <td>8ab97904e6daea8866dbdbc4fb7aad2c</td>
      <td>delivered</td>
      <td>2018-02-13 21:18:39</td>
      <td>2018-02-13 22:20:29</td>
      <td>2018-02-14 19:46:34</td>
      <td>2018-02-16 18:17:02</td>
      <td>2018-02-26 00:00:00</td>
    </tr>
  </tbody>
</table>
</div>




```python
products.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>product_id</th>
      <th>product_category_name</th>
      <th>product_name_lenght</th>
      <th>product_description_lenght</th>
      <th>product_photos_qty</th>
      <th>product_weight_g</th>
      <th>product_length_cm</th>
      <th>product_height_cm</th>
      <th>product_width_cm</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1e9e8ef04dbcff4541ed26657ea517e5</td>
      <td>perfumaria</td>
      <td>40.00</td>
      <td>287.00</td>
      <td>1.00</td>
      <td>225.00</td>
      <td>16.00</td>
      <td>10.00</td>
      <td>14.00</td>
    </tr>
    <tr>
      <th>1</th>
      <td>3aa071139cb16b67ca9e5dea641aaa2f</td>
      <td>artes</td>
      <td>44.00</td>
      <td>276.00</td>
      <td>1.00</td>
      <td>1000.00</td>
      <td>30.00</td>
      <td>18.00</td>
      <td>20.00</td>
    </tr>
    <tr>
      <th>2</th>
      <td>96bd76ec8810374ed1b65e291975717f</td>
      <td>esporte_lazer</td>
      <td>46.00</td>
      <td>250.00</td>
      <td>1.00</td>
      <td>154.00</td>
      <td>18.00</td>
      <td>9.00</td>
      <td>15.00</td>
    </tr>
    <tr>
      <th>3</th>
      <td>cef67bcfe19066a932b7673e239eb23d</td>
      <td>bebes</td>
      <td>27.00</td>
      <td>261.00</td>
      <td>1.00</td>
      <td>371.00</td>
      <td>26.00</td>
      <td>4.00</td>
      <td>26.00</td>
    </tr>
    <tr>
      <th>4</th>
      <td>9dc1a7de274444849c219cff195d0b71</td>
      <td>utilidades_domesticas</td>
      <td>37.00</td>
      <td>402.00</td>
      <td>4.00</td>
      <td>625.00</td>
      <td>20.00</td>
      <td>17.00</td>
      <td>13.00</td>
    </tr>
  </tbody>
</table>
</div>




```python
sellers.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>seller_id</th>
      <th>seller_zip_code_prefix</th>
      <th>seller_city</th>
      <th>seller_state</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>3442f8959a84dea7ee197c632cb2df15</td>
      <td>13023</td>
      <td>campinas</td>
      <td>SP</td>
    </tr>
    <tr>
      <th>1</th>
      <td>d1b65fc7debc3361ea86b5f14c68d2e2</td>
      <td>13844</td>
      <td>mogi guacu</td>
      <td>SP</td>
    </tr>
    <tr>
      <th>2</th>
      <td>ce3ad9de960102d0677a81f5d0bb7b2d</td>
      <td>20031</td>
      <td>rio de janeiro</td>
      <td>RJ</td>
    </tr>
    <tr>
      <th>3</th>
      <td>c0f3eea2e14555b6faeea3dd58c1b1c3</td>
      <td>4195</td>
      <td>sao paulo</td>
      <td>SP</td>
    </tr>
    <tr>
      <th>4</th>
      <td>51a04a8a6bdcb23deccc82b0b80742cf</td>
      <td>12914</td>
      <td>braganca paulista</td>
      <td>SP</td>
    </tr>
  </tbody>
</table>
</div>



O comando .shape revela que temos aproximadamente 100.000 registros de pedidos. O .head() confirma que a granularidade da tabela orders √© "um pedido por linha", mas para analisar Churn, precisaremos agrupar isso para a vis√£o de "cliente √∫nico", visto que um cliente pode ter feito m√∫ltiplos pedidos ao longo do tempo.

## Integridade Estrutural e Tipagem

A qualidade da nossa previs√£o de Churn depende diretamente da qualidade das nossas vari√°veis temporais (datas de compra).


```python
customers.info()
```

    <class 'pandas.core.frame.DataFrame'>
    RangeIndex: 99441 entries, 0 to 99440
    Data columns (total 5 columns):
     #   Column                    Non-Null Count  Dtype 
    ---  ------                    --------------  ----- 
     0   customer_id               99441 non-null  object
     1   customer_unique_id        99441 non-null  object
     2   customer_zip_code_prefix  99441 non-null  int64 
     3   customer_city             99441 non-null  object
     4   customer_state            99441 non-null  object
    dtypes: int64(1), object(4)
    memory usage: 3.8+ MB
    


```python
geolocation.info()
```

    <class 'pandas.core.frame.DataFrame'>
    RangeIndex: 1000163 entries, 0 to 1000162
    Data columns (total 5 columns):
     #   Column                       Non-Null Count    Dtype  
    ---  ------                       --------------    -----  
     0   geolocation_zip_code_prefix  1000163 non-null  int64  
     1   geolocation_lat              1000163 non-null  float64
     2   geolocation_lng              1000163 non-null  float64
     3   geolocation_city             1000163 non-null  object 
     4   geolocation_state            1000163 non-null  object 
    dtypes: float64(2), int64(1), object(2)
    memory usage: 38.2+ MB
    


```python
order_items.info()
```

    <class 'pandas.core.frame.DataFrame'>
    RangeIndex: 112650 entries, 0 to 112649
    Data columns (total 7 columns):
     #   Column               Non-Null Count   Dtype  
    ---  ------               --------------   -----  
     0   order_id             112650 non-null  object 
     1   order_item_id        112650 non-null  int64  
     2   product_id           112650 non-null  object 
     3   seller_id            112650 non-null  object 
     4   shipping_limit_date  112650 non-null  object 
     5   price                112650 non-null  float64
     6   freight_value        112650 non-null  float64
    dtypes: float64(2), int64(1), object(4)
    memory usage: 6.0+ MB
    


```python
order_payments.info()
```

    <class 'pandas.core.frame.DataFrame'>
    RangeIndex: 103886 entries, 0 to 103885
    Data columns (total 5 columns):
     #   Column                Non-Null Count   Dtype  
    ---  ------                --------------   -----  
     0   order_id              103886 non-null  object 
     1   payment_sequential    103886 non-null  int64  
     2   payment_type          103886 non-null  object 
     3   payment_installments  103886 non-null  int64  
     4   payment_value         103886 non-null  float64
    dtypes: float64(1), int64(2), object(2)
    memory usage: 4.0+ MB
    


```python
order_reviews.info()
```

    <class 'pandas.core.frame.DataFrame'>
    RangeIndex: 99224 entries, 0 to 99223
    Data columns (total 7 columns):
     #   Column                   Non-Null Count  Dtype 
    ---  ------                   --------------  ----- 
     0   review_id                99224 non-null  object
     1   order_id                 99224 non-null  object
     2   review_score             99224 non-null  int64 
     3   review_comment_title     11568 non-null  object
     4   review_comment_message   40977 non-null  object
     5   review_creation_date     99224 non-null  object
     6   review_answer_timestamp  99224 non-null  object
    dtypes: int64(1), object(6)
    memory usage: 5.3+ MB
    


```python
orders.info()
```

    <class 'pandas.core.frame.DataFrame'>
    RangeIndex: 99441 entries, 0 to 99440
    Data columns (total 8 columns):
     #   Column                         Non-Null Count  Dtype 
    ---  ------                         --------------  ----- 
     0   order_id                       99441 non-null  object
     1   customer_id                    99441 non-null  object
     2   order_status                   99441 non-null  object
     3   order_purchase_timestamp       99441 non-null  object
     4   order_approved_at              99281 non-null  object
     5   order_delivered_carrier_date   97658 non-null  object
     6   order_delivered_customer_date  96476 non-null  object
     7   order_estimated_delivery_date  99441 non-null  object
    dtypes: object(8)
    memory usage: 6.1+ MB
    


```python
products.info()
```

    <class 'pandas.core.frame.DataFrame'>
    RangeIndex: 32951 entries, 0 to 32950
    Data columns (total 9 columns):
     #   Column                      Non-Null Count  Dtype  
    ---  ------                      --------------  -----  
     0   product_id                  32951 non-null  object 
     1   product_category_name       32341 non-null  object 
     2   product_name_lenght         32341 non-null  float64
     3   product_description_lenght  32341 non-null  float64
     4   product_photos_qty          32341 non-null  float64
     5   product_weight_g            32949 non-null  float64
     6   product_length_cm           32949 non-null  float64
     7   product_height_cm           32949 non-null  float64
     8   product_width_cm            32949 non-null  float64
    dtypes: float64(7), object(2)
    memory usage: 2.3+ MB
    


```python
sellers.info()
```

    <class 'pandas.core.frame.DataFrame'>
    RangeIndex: 3095 entries, 0 to 3094
    Data columns (total 4 columns):
     #   Column                  Non-Null Count  Dtype 
    ---  ------                  --------------  ----- 
     0   seller_id               3095 non-null   object
     1   seller_zip_code_prefix  3095 non-null   int64 
     2   seller_city             3095 non-null   object
     3   seller_state            3095 non-null   object
    dtypes: int64(1), object(3)
    memory usage: 96.8+ KB
    

O output do .info() indica que as colunas de data foram carregadas como objetos (strings). Isso √© um risco cr√≠tico. N√£o podemos calcular Rec√™ncia ou Coortes sem converter essas colunas para datetime. A√ß√£o Imediata: Convers√£o de todas as colunas temporais.

## An√°lise Estat√≠stica Descritiva

Ao aplicarmos estat√≠stica descritiva, buscamos entender a dispers√£o dos dados financeiros e log√≠sticos.


```python
customers.describe()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>customer_zip_code_prefix</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>99441.00</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>35137.47</td>
    </tr>
    <tr>
      <th>std</th>
      <td>29797.94</td>
    </tr>
    <tr>
      <th>min</th>
      <td>1003.00</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>11347.00</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>24416.00</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>58900.00</td>
    </tr>
    <tr>
      <th>max</th>
      <td>99990.00</td>
    </tr>
  </tbody>
</table>
</div>




```python
geolocation.describe()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>geolocation_zip_code_prefix</th>
      <th>geolocation_lat</th>
      <th>geolocation_lng</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>1000163.00</td>
      <td>1000163.00</td>
      <td>1000163.00</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>36574.17</td>
      <td>-21.18</td>
      <td>-46.39</td>
    </tr>
    <tr>
      <th>std</th>
      <td>30549.34</td>
      <td>5.72</td>
      <td>4.27</td>
    </tr>
    <tr>
      <th>min</th>
      <td>1001.00</td>
      <td>-36.61</td>
      <td>-101.47</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>11075.00</td>
      <td>-23.60</td>
      <td>-48.57</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>26530.00</td>
      <td>-22.92</td>
      <td>-46.64</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>63504.00</td>
      <td>-19.98</td>
      <td>-43.77</td>
    </tr>
    <tr>
      <th>max</th>
      <td>99990.00</td>
      <td>45.07</td>
      <td>121.11</td>
    </tr>
  </tbody>
</table>
</div>




```python
order_items.describe()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>order_item_id</th>
      <th>price</th>
      <th>freight_value</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>112650.00</td>
      <td>112650.00</td>
      <td>112650.00</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>1.20</td>
      <td>120.65</td>
      <td>19.99</td>
    </tr>
    <tr>
      <th>std</th>
      <td>0.71</td>
      <td>183.63</td>
      <td>15.81</td>
    </tr>
    <tr>
      <th>min</th>
      <td>1.00</td>
      <td>0.85</td>
      <td>0.00</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>1.00</td>
      <td>39.90</td>
      <td>13.08</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>1.00</td>
      <td>74.99</td>
      <td>16.26</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>1.00</td>
      <td>134.90</td>
      <td>21.15</td>
    </tr>
    <tr>
      <th>max</th>
      <td>21.00</td>
      <td>6735.00</td>
      <td>409.68</td>
    </tr>
  </tbody>
</table>
</div>




```python
order_payments.describe()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>payment_sequential</th>
      <th>payment_installments</th>
      <th>payment_value</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>103886.00</td>
      <td>103886.00</td>
      <td>103886.00</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>1.09</td>
      <td>2.85</td>
      <td>154.10</td>
    </tr>
    <tr>
      <th>std</th>
      <td>0.71</td>
      <td>2.69</td>
      <td>217.49</td>
    </tr>
    <tr>
      <th>min</th>
      <td>1.00</td>
      <td>0.00</td>
      <td>0.00</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>1.00</td>
      <td>1.00</td>
      <td>56.79</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>1.00</td>
      <td>1.00</td>
      <td>100.00</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>1.00</td>
      <td>4.00</td>
      <td>171.84</td>
    </tr>
    <tr>
      <th>max</th>
      <td>29.00</td>
      <td>24.00</td>
      <td>13664.08</td>
    </tr>
  </tbody>
</table>
</div>




```python
order_reviews.describe()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>review_score</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>99224.00</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>4.09</td>
    </tr>
    <tr>
      <th>std</th>
      <td>1.35</td>
    </tr>
    <tr>
      <th>min</th>
      <td>1.00</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>4.00</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>5.00</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>5.00</td>
    </tr>
    <tr>
      <th>max</th>
      <td>5.00</td>
    </tr>
  </tbody>
</table>
</div>




```python
orders.describe()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>order_id</th>
      <th>customer_id</th>
      <th>order_status</th>
      <th>order_purchase_timestamp</th>
      <th>order_approved_at</th>
      <th>order_delivered_carrier_date</th>
      <th>order_delivered_customer_date</th>
      <th>order_estimated_delivery_date</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>99441</td>
      <td>99441</td>
      <td>99441</td>
      <td>99441</td>
      <td>99281</td>
      <td>97658</td>
      <td>96476</td>
      <td>99441</td>
    </tr>
    <tr>
      <th>unique</th>
      <td>99441</td>
      <td>99441</td>
      <td>8</td>
      <td>98875</td>
      <td>90733</td>
      <td>81018</td>
      <td>95664</td>
      <td>459</td>
    </tr>
    <tr>
      <th>top</th>
      <td>66dea50a8b16d9b4dee7af250b4be1a5</td>
      <td>edb027a75a1449115f6b43211ae02a24</td>
      <td>delivered</td>
      <td>2018-08-02 12:06:07</td>
      <td>2018-02-27 04:31:10</td>
      <td>2018-05-09 15:48:00</td>
      <td>2018-05-14 20:02:44</td>
      <td>2017-12-20 00:00:00</td>
    </tr>
    <tr>
      <th>freq</th>
      <td>1</td>
      <td>1</td>
      <td>96478</td>
      <td>3</td>
      <td>9</td>
      <td>47</td>
      <td>3</td>
      <td>522</td>
    </tr>
  </tbody>
</table>
</div>




```python
products.describe()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>product_name_lenght</th>
      <th>product_description_lenght</th>
      <th>product_photos_qty</th>
      <th>product_weight_g</th>
      <th>product_length_cm</th>
      <th>product_height_cm</th>
      <th>product_width_cm</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>32341.00</td>
      <td>32341.00</td>
      <td>32341.00</td>
      <td>32949.00</td>
      <td>32949.00</td>
      <td>32949.00</td>
      <td>32949.00</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>48.48</td>
      <td>771.50</td>
      <td>2.19</td>
      <td>2276.47</td>
      <td>30.82</td>
      <td>16.94</td>
      <td>23.20</td>
    </tr>
    <tr>
      <th>std</th>
      <td>10.25</td>
      <td>635.12</td>
      <td>1.74</td>
      <td>4282.04</td>
      <td>16.91</td>
      <td>13.64</td>
      <td>12.08</td>
    </tr>
    <tr>
      <th>min</th>
      <td>5.00</td>
      <td>4.00</td>
      <td>1.00</td>
      <td>0.00</td>
      <td>7.00</td>
      <td>2.00</td>
      <td>6.00</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>42.00</td>
      <td>339.00</td>
      <td>1.00</td>
      <td>300.00</td>
      <td>18.00</td>
      <td>8.00</td>
      <td>15.00</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>51.00</td>
      <td>595.00</td>
      <td>1.00</td>
      <td>700.00</td>
      <td>25.00</td>
      <td>13.00</td>
      <td>20.00</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>57.00</td>
      <td>972.00</td>
      <td>3.00</td>
      <td>1900.00</td>
      <td>38.00</td>
      <td>21.00</td>
      <td>30.00</td>
    </tr>
    <tr>
      <th>max</th>
      <td>76.00</td>
      <td>3992.00</td>
      <td>20.00</td>
      <td>40425.00</td>
      <td>105.00</td>
      <td>105.00</td>
      <td>118.00</td>
    </tr>
  </tbody>
</table>
</div>




```python
sellers.describe()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>seller_zip_code_prefix</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>3095.00</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>32291.06</td>
    </tr>
    <tr>
      <th>std</th>
      <td>32713.45</td>
    </tr>
    <tr>
      <th>min</th>
      <td>1001.00</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>7093.50</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>14940.00</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>64552.50</td>
    </tr>
    <tr>
      <th>max</th>
      <td>99730.00</td>
    </tr>
  </tbody>
</table>
</div>



* **Vari√°veis Cont√≠nuas:** Observamos a m√©dia e os quartis. H√° uma grande diferen√ßa entre o valor m√°ximo e o terceiro quartil? Isso indicaria a presen√ßa de outliers que podem distorcer a m√©dia. Em modelos de Churn, outliers financeiros podem representar clientes B2B ou revendedores, que t√™m comportamento diferente de consumidores finais.
* **Vari√°veis Discretas:** Ao analisar order_item_id, podemos ver quantos itens comp√µem tipicamente uma cesta.

## Entendendo a Distor√ß√£o dos Dados

Em projetos de Churn, a distribui√ß√£o dos dados quase nunca √© uma curva normal perfeita.

1. **Distor√ß√£o em Vari√°veis Num√©ricas:** Dados financeiros geralmente apresentam uma distribui√ß√£o de cauda longa, onde poucos clientes gastam muito. Aplicar transforma√ß√µes pode ser necess√°rio para modelos lineares.
2. **Desbalanceamento da Classe:** A quest√£o mais cr√≠tica √© a propor√ß√£o de Churn. No caso da Olist, a maioria dos clientes pode comprar apenas uma vez.


```python
numeric_features = ['geolocation_lat', 'geolocation_lng']
df = geolocation

plt.figure(figsize=(15, 6))
plt.suptitle("An√°lise Univariada - Geolocaliza√ß√£o", fontsize=20, fontweight='bold', alpha=0.8, y=1.05)

for i in range(len(numeric_features)):
    plt.subplot(1, 2, i+1)
    sns.kdeplot(x=df[numeric_features[i]].dropna(), fill=True, color='b')
    plt.xlabel(numeric_features[i])
    plt.tight_layout()

plt.show()
```


    
![png](diagn-stico-de-churn-e-commerce-brasileiro_files/diagn-stico-de-churn-e-commerce-brasileiro_68_0.png)
    



```python
numeric_features = ['price', 'freight_value']
df = order_items

plt.figure(figsize=(15, 6))
plt.suptitle("An√°lise Univariada - Itens do Pedido", fontsize=20, fontweight='bold', alpha=0.8, y=1.05)

for i in range(len(numeric_features)):
    plt.subplot(1, 2, i+1)
    sns.kdeplot(x=df[numeric_features[i]].dropna(), fill=True, color='b') 
    plt.xlabel(numeric_features[i])
    plt.tight_layout()

plt.show()
```


    
![png](diagn-stico-de-churn-e-commerce-brasileiro_files/diagn-stico-de-churn-e-commerce-brasileiro_69_0.png)
    



```python
numeric_features = ['payment_value']
df = order_payments

plt.figure(figsize=(10, 6))
plt.suptitle("An√°lise Univariada - Pagamentos", fontsize=20, fontweight='bold', alpha=0.8, y=1.05)

for i in range(len(numeric_features)):
    plt.subplot(1, 1, i+1)
    sns.kdeplot(x=df[numeric_features[i]].dropna(), fill=True, color='b')
    plt.xlabel(numeric_features[i])
    plt.tight_layout()

plt.show()
```


    
![png](diagn-stico-de-churn-e-commerce-brasileiro_files/diagn-stico-de-churn-e-commerce-brasileiro_70_0.png)
    



```python
numeric_features = ['product_weight_g', 'product_length_cm', 'product_height_cm', 'product_width_cm']
df = products

plt.figure(figsize=(15, 10))
plt.suptitle("An√°lise Univariada - Produtos", fontsize=20, fontweight='bold', alpha=0.8, y=1.02)

for i in range(len(numeric_features)):
    plt.subplot(2, 2, i+1)
    sns.kdeplot(x=df[numeric_features[i]].dropna(), fill=True, color='b')
    plt.xlabel(numeric_features[i])
    plt.tight_layout()

plt.show()
```


    
![png](diagn-stico-de-churn-e-commerce-brasileiro_files/diagn-stico-de-churn-e-commerce-brasileiro_71_0.png)
    



```python
cat_customers = ['customer_state']

plt.figure(figsize=(20, 8))
plt.suptitle("An√°lise Univariada - Clientes", fontsize=20, fontweight='bold', alpha=0.8, y=1.)

for i in range(len(cat_customers)):
    plt.subplot(1, 1, i+1)
    
    sns.countplot(
        x=customers[cat_customers[i]], 
        palette='viridis',
        order=customers[cat_customers[i]].value_counts().index
    )
    
    plt.xlabel(cat_customers[i])
    plt.xticks(rotation=45)
    plt.tight_layout()

plt.show()
```


    
![png](diagn-stico-de-churn-e-commerce-brasileiro_files/diagn-stico-de-churn-e-commerce-brasileiro_72_0.png)
    



```python
# Definindo as features categ√≥ricas/discretas deste dataset
cat_payments = ['payment_type', 'payment_installments']

# Configura√ß√£o da figura
plt.figure(figsize=(20, 8))
plt.suptitle("An√°lise Univariada - Pagamentos", fontsize=20, fontweight='bold', alpha=0.8, y=1.)

for i in range(len(cat_payments)):
    plt.subplot(1, len(cat_payments), i+1) 
    
    sns.countplot(x=order_payments[cat_payments[i]], palette='viridis')
    
    plt.xlabel(cat_payments[i])
    plt.xticks(rotation=45)
    plt.tight_layout()

plt.show()
```


    
![png](diagn-stico-de-churn-e-commerce-brasileiro_files/diagn-stico-de-churn-e-commerce-brasileiro_73_0.png)
    



```python
cat_reviews = ['review_score']

plt.figure(figsize=(15, 8))
plt.suptitle("An√°lise Univariada - Reviews", fontsize=20, fontweight='bold', alpha=0.8, y=1.)

for i in range(len(cat_reviews)):
    plt.subplot(1, 1, i+1)
    
    sns.countplot(x=order_reviews[cat_reviews[i]], palette='viridis')
    
    plt.xlabel(cat_reviews[i])
    plt.xticks(rotation=0)
    plt.tight_layout()

plt.show()
```


    
![png](diagn-stico-de-churn-e-commerce-brasileiro_files/diagn-stico-de-churn-e-commerce-brasileiro_74_0.png)
    



```python
cat_orders = ['order_status']

plt.figure(figsize=(15, 8))
plt.suptitle("An√°lise Univariada - Pedidos", fontsize=20, fontweight='bold', alpha=0.8, y=1.)

for i in range(len(cat_orders)):
    plt.subplot(1, 1, i+1)
    
    sns.countplot(
        x=orders[cat_orders[i]], 
        palette='viridis',
        order=orders[cat_orders[i]].value_counts().index
    )
    
    plt.xlabel(cat_orders[i])
    plt.xticks(rotation=45)
    plt.yscale('log') 
    plt.tight_layout()

plt.show()
```


    
![png](diagn-stico-de-churn-e-commerce-brasileiro_files/diagn-stico-de-churn-e-commerce-brasileiro_75_0.png)
    


O churn n√£o afeta todos os grupos igualmente. Investigamos as vari√°veis categ√≥ricas para entender a granularidade da base.

* **Descoberta:** A cardinalidade dessas vari√°veis exigiu aten√ß√£o. Por exemplo, existem dezenas de categorias de produtos e m√∫ltiplos estados. Simplesmente converter tudo para n√∫meros (Label Encoding) poderia criar uma falsa ordem de grandeza; portanto, planejamos estrat√©gias como One-Hot Encoding para vari√°veis de baixa cardinalidade (como sexo ou status), garantindo que o modelo matem√°tico entenda as nuances qualitativas do neg√≥cio.

# Processo

## A Arquitetura da Solu√ß√£o: Do Caos Relacional √† Vis√£o Unificada do Cliente

O desafio inicial deste projeto n√£o foi a aus√™ncia de dados, mas a sua fragmenta√ß√£o. O ecossistema Olist √© distribu√≠do em um esquema relacional complexo composto por 9 tabelas distintas, onde pedidos, pagamentos, avalia√ß√µes e geolocaliza√ß√£o vivem em silos separados. Para diagnosticar o churn, precis√°vamos transitar de uma vis√£o centrada em "Transa√ß√µes" para uma vis√£o centrada no "Cliente".

A primeira decis√£o cr√≠tica de arquitetura foi a Resolu√ß√£o de Entidade. No dataset da Olist, a coluna customer_id representa a chave de uma sess√£o de compra, n√£o o indiv√≠duo. Seguir esse identificador cegamente levaria √† conclus√£o err√¥nea de que cada venda prov√©m de um novo consumidor. Para reconstruir a jornada real, realizamos o mapeamento para o customer_unique_id, o que nos permitiu unificar m√∫ltiplos pedidos sob um √∫nico perfil e rastrear a fidelidade real ao longo do tempo.
A estrat√©gia de Unifica√ß√£o dos Dataframes seguiu uma l√≥gica sequencial rigorosa:

1. **Base:** Conex√£o entre Clientes e Pedidos para estabelecer a cronologia.
2. **Qualidade:** Jun√ß√£o com Reviews para capturar a voz do cliente e o sentimento.
3. **Financeiro:** Integra√ß√£o com Pagamentos para entender o comportamento de gasto.
4. **Granularidade:** Explos√£o para Itens e Produtos, permitindo analisar se categorias espec√≠ficas possuem ciclos de vida diferentes.


```python
# Agrega√ß√£o de Pagamentos
pay_agg = order_payments.groupby('order_id').agg({
    'payment_sequential': 'max',
    'payment_installments': 'max',
    'payment_value': 'sum',
    'payment_type': 'first' 
}).reset_index()
pay_agg.rename(columns={'payment_value': 'total_paid_real'}, inplace=True)

# Agrega√ß√£o de Reviews
reviews_agg = order_reviews.groupby('order_id').agg({
    'review_score': 'mean', 
    'review_comment_message': 'first'
}).reset_index()

# 1 Base
df_master = orders.merge(customers, on='customer_id', how='inner')

# 2 Reviews
df_master = df_master.merge(reviews_agg, on='order_id', how='left')

# 3 Pagamentos 
df_master = df_master.merge(pay_agg, on='order_id', how='left')

# 4 Itens
df_master = df_master.merge(order_items, on='order_id', how='left')

# 5 Produtos
df_master = df_master.merge(products, on='product_id', how='left')

# 6 Vendedores
df_master = df_master.merge(sellers, on='seller_id', how='left', suffixes=('_cust', '_seller'))
```


```python
geolocation = geolocation[
    (geolocation.geolocation_lat <= 5) & (geolocation.geolocation_lat >= -34) &
    (geolocation.geolocation_lng <= -34) & (geolocation.geolocation_lng >= -74)
]

geo_unique = geolocation.groupby("geolocation_zip_code_prefix").agg({
    "geolocation_lat": "mean",
    "geolocation_lng": "mean",
    "geolocation_city": "first",
    "geolocation_state": "first"
}).reset_index()

geo_unique.rename(columns={"geolocation_zip_code_prefix": "zip_code_prefix"}, inplace=True)
```

## Engenharia da Defini√ß√£o de Churn: Decodificando o Sil√™ncio

Em servi√ßos de assinatura (como Netflix), o churn √© um evento expl√≠cito: o cliente cancela o contrato. No varejo n√£o contratual da Olist, o abandono √© silencioso; o cliente simplesmente n√£o volta. O grande desafio desta etapa foi: **como definir um modelo para prever o sil√™ncio?**

N√£o adotamos uma janela arbitr√°ria (como "30 dias sem comprar"). Em vez disso, deixamos os dados falarem atrav√©s da an√°lise da distribui√ß√£o do tempo entre compras. Observamos que o comportamento padr√£o na Olist √© o de "comprador √∫nico" (One-and-Done), com taxas de churn intr√≠nsecas alt√≠ssimas, superando 96% em algumas coortes.

Definimos o churn inferido aplicando uma janela de inatividade baseada em percentis estat√≠sticos sobre a Rec√™ncia. Se um cliente ultrapassa esse limiar de sil√™ncio sem realizar uma nova transa√ß√£o, ele √© rotulado como churn. Essa engenharia da vari√°vel alvo transformou um problema de comportamento amb√≠guo em um problema de classifica√ß√£o supervisionada claro.


```python
df_master['order_purchase_timestamp'] = pd.to_datetime(df_master['order_purchase_timestamp'])

df_sorted = df_master.sort_values(['customer_unique_id', 'order_purchase_timestamp'])
df_orders_unique = df_sorted.drop_duplicates(subset='order_id')

# Calcular dias entre compras
df_orders_unique['prev_order_date'] = df_orders_unique.groupby('customer_unique_id')['order_purchase_timestamp'].shift(1)
df_orders_unique['days_diff'] = (df_orders_unique['order_purchase_timestamp'] - df_orders_unique['prev_order_date']).dt.days

# Estat√≠sticas para definir o corte
df_recorrentes = df_orders_unique.dropna(subset=['days_diff'])
stats = df_recorrentes['days_diff'].describe(percentiles=[0.90, 0.95])

# Visualiza√ß√£o da Cauda Longa 
plt.figure(figsize=(12, 6))
sns.histplot(df_recorrentes['days_diff'], bins=50, kde=True, color='navy')
plt.title('Distribui√ß√£o do Tempo Entre Compras (Base para Defini√ß√£o de Churn)')
plt.xlabel('Dias entre compras')
plt.show()

# Defini√ß√£o do Limiar
limite_estatistico = int(stats['95%'])
churn_threshold = min(limite_estatistico, 365)
print(f"Limiar de Churn Definido: {churn_threshold} dias")

max_date = df_master['order_purchase_timestamp'].max() + pd.Timedelta(days=1)

df_target = df_master.groupby('customer_unique_id').agg({
    'order_purchase_timestamp': 'max',  
    'order_id': 'nunique',              
    'price': 'sum'                     
}).reset_index()

# Renomear
df_target.rename(columns={
    'order_purchase_timestamp': 'data_ultima_compra',
    'order_id': 'frequencia_total',
    'price': 'monetary_value'
}, inplace=True)

# Calcular Rec√™ncia e aplicar a Flag
df_target['recencia_dias'] = (max_date - df_target['data_ultima_compra']).dt.days
df_target['flg_churn'] = df_target['recencia_dias'] > churn_threshold
df_target['segmento_frequencia'] = np.where(df_target['frequencia_total'] > 1, 'Recorrente', 'One-Time Buyer')

colunas_para_adicionar = ['customer_unique_id', 'flg_churn', 'recencia_dias', 'frequencia_total', 'segmento_frequencia']

df_eda_final = df_master.merge(df_target[colunas_para_adicionar], 
                               on='customer_unique_id', 
                               how='left')
```


    
![png](diagn-stico-de-churn-e-commerce-brasileiro_files/diagn-stico-de-churn-e-commerce-brasileiro_84_0.png)
    


    Limiar de Churn Definido: 312 dias
    

## Engenharia de Atributos (Feature Engineering)

Com a base limpa e o alvo definido, o foco mudou para explicar os porqu√™s. A engenharia de atributos buscou traduzir logs operacionais em sinais de comportamento humano:
* **Log√≠stica e Ansiedade:** Calculamos o delta_delivery. Estudos indicam que atrasos transformam promotores em detratores instantaneamente. Criamos tamb√©m flags de atraso para quantificar o impacto da log√≠stica na reten√ß√£o.
* **Valor e Engajamento (RFM):** Implementamos m√©tricas de Rec√™ncia, Frequ√™ncia e Valor Monet√°rio para segmentar clientes n√£o apenas pelo que gastam, mas pelo risco de inatividade. Isso permite identificar "Baleias" (clientes VIP) que est√£o em risco de abandonar a plataforma.
* **Dist√¢ncia e Geografia:** Utilizando as coordenadas de latitude/longitude, calculamos a dist√¢ncia entre vendedor e comprador. No contexto brasileiro, o custo do frete √© decisivo; essa feature nos permite testar se a dist√¢ncia f√≠sica est√° correlacionada com a desist√™ncia futura.
* **Sentimento:** Integramos as notas de avalia√ß√£o (1-5) como preditores diretos. Uma nota baixa na primeira compra √©, frequentemente, o sinal definitivo de churn.


```python
date_cols = ['order_purchase_timestamp', 'order_approved_at', 
             'order_delivered_carrier_date', 'order_delivered_customer_date', 
             'order_estimated_delivery_date', 'shipping_limit_date']

for col in date_cols:
    if col in df_eda_final.columns:
        df_eda_final[col] = pd.to_datetime(df_eda_final[col], errors='coerce')

# Dias de atraso (Negativo = Adiantado, Positivo = Atrasado)
df_eda_final['delivery_delta_days'] = (df_eda_final['order_delivered_customer_date'] - df_eda_final['order_estimated_delivery_date']).dt.days

# Criamos uma flag para identificar pedidos n√£o entregues
df_eda_final['is_lost_or_processing'] = df_eda_final['order_delivered_customer_date'].isnull().astype(int)

df_eda_final['is_delayed'] = np.where(
    (df_eda_final['delivery_delta_days'] > 0) | (df_eda_final['is_lost_or_processing'] == 1), 
    1, 0
)

df_eda_final['seller_late_to_post'] = np.where(
    df_eda_final['order_delivered_carrier_date'] > df_eda_final['shipping_limit_date'], 1, 0
)

conditions = [
    (df_eda_final['review_score'] <= 2),
    (df_eda_final['review_score'] == 3),
    (df_eda_final['review_score'] >= 4)
]
choices = ['Detractor', 'Passive', 'Promoter']
df_eda_final['nps_class'] = np.select(conditions, choices, default='No_Review')

# NLP B√°sico
df_eda_final['review_comment_message'] = df_eda_final['review_comment_message'].fillna('').astype(str).str.lower()
df_eda_final['complain_delivery'] = df_eda_final['review_comment_message'].str.contains('atras|demor|esper|nunca|chegou', regex=True).astype(int)
df_eda_final['complain_product'] = df_eda_final['review_comment_message'].str.contains('defeito|quebrad|errado|troca|ruim|p√©ssim', regex=True).astype(int)

df_eda_final['freight_ratio'] = df_eda_final['freight_value'] / (df_eda_final['price'] + df_eda_final['freight_value'] + 0.01)

if 'payment_type' in df_eda_final.columns:
    df_eda_final['is_boleto'] = np.where(df_eda_final['payment_type'] == 'boleto', 1, 0)
else:
    df_eda_final['is_boleto'] = 0 

df_eda_final = df_eda_final.merge(geo_unique, left_on='customer_zip_code_prefix', right_on='zip_code_prefix', how='left')
df_eda_final.rename(columns={'geolocation_lat': 'lat_cust', 'geolocation_lng': 'lng_cust'}, inplace=True)
df_eda_final.drop(columns=['zip_code_prefix'], inplace=True, errors='ignore')

df_eda_final = df_eda_final.merge(geo_unique, left_on='seller_zip_code_prefix', right_on='zip_code_prefix', how='left')
df_eda_final.rename(columns={'geolocation_lat': 'lat_seller', 'geolocation_lng': 'lng_seller'}, inplace=True)
df_eda_final.drop(columns=['zip_code_prefix'], inplace=True, errors='ignore')

def haversine_vectorized(lat1, lon1, lat2, lon2):
    R = 6371  
    phi1, phi2 = np.radians(lat1), np.radians(lat2)
    dphi = np.radians(lat2 - lat1)
    dlambda = np.radians(lon2 - lon1)
    a = np.sin(dphi/2)**2 + np.cos(phi1) * np.cos(phi2) * np.sin(dlambda/2)**2
    a = np.clip(a, 0, 1)
    return 2 * R * np.arcsin(np.sqrt(a))

mask_geo = df_eda_final['lat_cust'].notna() & df_eda_final['lat_seller'].notna()
df_eda_final.loc[mask_geo, 'distance_km'] = haversine_vectorized(
    df_eda_final.loc[mask_geo, 'lat_cust'], 
    df_eda_final.loc[mask_geo, 'lng_cust'], 
    df_eda_final.loc[mask_geo, 'lat_seller'], 
    df_eda_final.loc[mask_geo, 'lng_seller']
)

cols_to_drop = ['lat_cust', 'lng_cust', 'lat_seller', 'lng_seller']
df_eda_final.drop(columns=[c for c in cols_to_drop if c in df_eda_final.columns], inplace=True)
```

## Limpeza e Qualidade de Dados

Dados do mundo real s√£o ruidosos, mas nem todo ru√≠do deve ser silenciado. Durante a etapa de saneamento, adotamos uma postura investigativa em vez de apenas deletar valores nulos.

Um exemplo crucial foi o tratamento das datas de entrega. Identificamos que valores nulos nesta coluna n√£o eram necessariamente erros de sistema, mas indicativos de pedidos em tr√¢nsito, extraviados ou cancelados. Remover essas linhas seria um erro metodol√≥gico grave, pois a falha na entrega √© um dos vetores mais fortes de churn. Em vez da exclus√£o, criamos flags informativas para capturar essa fric√ß√£o log√≠stica.

Para os dados textuais de reviews, onde cerca de 58% dos coment√°rios eram nulos, realizamos a imputa√ß√£o com marcadores neutros ("Sem Coment√°rio"), preservando a integridade das notas num√©ricas (review_score) que servem como term√¥metro soberano da satisfa√ß√£o.

**Tratamento de Datas**


```python
df_cleaned = df_eda_final

date_cols = [
    'order_purchase_timestamp', 
    'order_approved_at', 
    'order_delivered_carrier_date', 
    'order_delivered_customer_date', 
    'order_estimated_delivery_date',
    'shipping_limit_date'
]

for col in date_cols:
    if col in df.columns:

        df_cleaned[col] = pd.to_datetime(df_cleaned[col], errors='coerce')

mask_erro_tempo = df_cleaned['order_delivered_customer_date'] < df_cleaned['order_purchase_timestamp']
df_cleaned = df_cleaned[~mask_erro_tempo]
```

**Tratamento de Nulos**


```python
df_cleaned['flg_entregue'] = df_cleaned['order_delivered_customer_date'].notna().astype(int)
df_cleaned['order_delivered_customer_date'].isna().sum()
```




    np.int64(3229)



**Remo√ß√£o de Ru√≠do**


```python
status_to_drop = ['unavailable', 'created', 'invoiced', 'processing', 'approved']
df_cleaned = df_cleaned[~df_cleaned['order_status'].isin(status_to_drop)]
```

**Imputa√ß√£o de Reviews**


```python
df_cleaned['review_comment_message'] = df_cleaned['review_comment_message'].fillna('Sem Coment√°rio')
```

**Remo√ß√£o de Linhas sem Geografia**


```python
df_cleaned = df_cleaned.dropna(subset=['distance_km'])
```

**Padroniza√ß√£o de Texto**


```python
cols_texto = ['customer_city', 'seller_city', 'product_category_name']

def padronizar_str(texto):
    if isinstance(texto, str):
        return unidecode.unidecode(texto).lower().strip()
    return texto

for col in cols_texto:
    if col in df_cleaned.columns:
        df_cleaned[col] = df_cleaned[col].apply(padronizar_str)
```

**Tratamento de Outiliers**


```python
def marcar_outliers(df_cleaned, col):
    Q1 = df_cleaned[col].quantile(0.25)
    Q3 = df_cleaned[col].quantile(0.75)
    IQR = Q3 - Q1
    limite_superior = Q3 + 1.5 * IQR
    
    outlier_col = f'is_outlier_{col}'
    df[outlier_col] = np.where(df[col] > limite_superior, 1, 0)
    
    qtd = df[outlier_col].sum()
    return df

if 'price' in df.columns:
    df = marcar_outliers(df_cleaned, 'price')
if 'freight_value' in df.columns:
    df = marcar_outliers(df_cleaned, 'freight_value')
```


```python
df_cleaned['product_category_name'] = df_cleaned['product_category_name'].fillna('outros')

cols_audit = ['product_weight_g', 'payment_sequential', 'payment_installments']
df_cleaned = df_cleaned.dropna(subset=cols_audit)

if 'seller_zip_code_prefix' in df_cleaned.columns:
    df_cleaned['seller_zip_code_prefix'] = df_cleaned['seller_zip_code_prefix'].astype(int)
```

# Analisar

## **O Perfil Estat√≠stico do Desequil√≠brio**

### **Distribui√ß√£o da Vari√°vel Target**

**Por que estou fazendo este gr√°fico?**

Estou construindo esta visualiza√ß√£o para estabelecer o cen√°rio base de sobreviv√™ncia da empresa e validar a integridade da engenharia de dados. Em modelos n√£o contratuais, h√° um risco cr√≠tico de confundir transa√ß√µes (sess√µes) com relacionamentos (indiv√≠duos). Este gr√°fico serve como a "prova real" de que a Resolu√ß√£o de Entidade foi executada corretamente ‚Äî mapeando customer_id para customer_unique_id. Sem isso, a taxa de churn seria falsamente reportada como 100%. Al√©m disso, ele nivela a expectativa dos stakeholders: antes de falarmos de crescimento, precisamos encarar a realidade da reten√ß√£o.


```python
df_freq = df_cleaned.groupby('customer_unique_id').agg({'order_id': 'nunique'}).reset_index()
df_freq.columns = ['customer_unique_id', 'frequency']

df_freq['perfil_compra'] = df_freq['frequency'].apply(
    lambda x: 'Compra √önica' if x == 1 else 'Recorrente'
)

contagem = df_freq['perfil_compra'].value_counts().sort_values(ascending=False)
values = contagem.values
labels = contagem.index

plt.figure(figsize=(12, 8))
sns.set_style("white")

colors = ['red', 'blue'] 

explode = (0.1, 0) 

wedges, texts, autotexts = plt.pie(
    values, 
    labels=labels, 
    autopct='%1.2f%%', 
    startangle=10,            
    colors=colors, 
    explode=explode, 
    shadow=False, 
    pctdistance=0.75,         
    labeldistance=1.15,       
    textprops={'fontsize': 13, 'color': 'black', 'weight': 'bold'}
)

for autotext in autotexts:
    autotext.set_color('white')
    autotext.set_fontsize(14)
    autotext.set_weight('bold')
    autotext.set_path_effects([path_effects.withStroke(linewidth=2, foreground='black')])

plt.title('A "Armadilha Transacional":\nApenas uma pequena fra√ß√£o ret√©m.', fontsize=18, fontweight='bold', loc='center')
plt.suptitle(f'An√°lise de {sum(values):,} Clientes √önicos', fontsize=12, color='gray')

plt.axis('equal')
plt.tight_layout()
plt.show()
```


    
![png](diagn-stico-de-churn-e-commerce-brasileiro_files/diagn-stico-de-churn-e-commerce-brasileiro_109_0.png)
    


**O que este gr√°fico nos diz?**

Este gr√°fico confirma o sucesso da Resolu√ß√£o de Entidade. Identificamos que 97% das transa√ß√µes pertencem a indiv√≠duos √∫nicos, validando que n√£o estamos inflando m√©tricas de novos usu√°rios ao confundir compras recorrentes com novos clientes.

2. **A Realidade do "Monoconsumo":** Operamos em um cen√°rio de desequil√≠brio severo. A base √© majoritariamente formada por "One-Time Buyers" (96,96%). Apenas 3% dos clientes geraram recompra hist√≥rica.

3. **Implica√ß√£o Estrat√©gica:** Financeiramente, isso classifica o neg√≥cio como transacional, n√£o relacional.

    * **O risco:** N√£o podemos depender do LTV (Lifetime Value) para recuperar o investimento.

    * **A regra:** O CAC precisa, obrigatoriamente, ser pago com a margem de contribui√ß√£o da primeira venda. Qualquer estrat√©gia que dependa de "recuperar o custo ao longo do tempo" resultar√° em preju√≠zo, dado que a reten√ß√£o √© a exce√ß√£o, n√£o a regra.

### **Histograma de Rec√™ncia**

**Por que estou fazendo este gr√°fico?**

Estou plotando a distribui√ß√£o de rec√™ncia para dar forma vis√≠vel ao "Churn Silencioso". No e-commerce, o cliente n√£o telefona para cancelar; ele simplesmente silencia. Este gr√°fico substitui "palpites" arbitr√°rios (como "acho que 90 dias √© churn") por uma defini√ß√£o guiada por dados. Ao visualizar a cauda longa da inatividade, buscamos identificar a fronteira exata entre um cliente "adormecido" (recuper√°vel) e um cliente "morto" (perda permanente), permitindo segmentar o or√ßamento de marketing com precis√£o cir√∫rgica.


```python
sns.set_style("white")
plt.rcParams['font.family'] = 'sans-serif'
COLOR_ACTIVE = 'dodgerblue'
COLOR_DANGER = 'red'

snapshot_date = df_cleaned['order_purchase_timestamp'].max() + pd.Timedelta(days=1)

df_recency = df_cleaned.groupby('customer_unique_id')['order_purchase_timestamp'].max().reset_index()
df_recency.columns = ['customer_unique_id', 'last_purchase']
df_recency['recencia_dias'] = (snapshot_date - df_recency['last_purchase']).dt.days

plt.figure(figsize=(12, 6))

# Histograma com KDE
ax = sns.histplot(
    data=df_recency,
    x='recencia_dias',
    bins=60,
    kde=True,
    color=COLOR_ACTIVE,
    alpha=0.6,
    edgecolor=None
)

# Defini√ß√£o do Limite de Churn
churn_threshold = 312 

# Linha Vertical de Corte
plt.axvline(
    x=churn_threshold, 
    color=COLOR_DANGER, 
    linestyle='--', 
    linewidth=2, 
    label=f'Limite de Churn ({churn_threshold} dias)' # Texto que aparecer√° na legenda
)

plt.legend(loc='upper right', frameon=False, fontsize=10)

y_max = ax.get_ylim()[1] 

# Zona de Oportunidade
plt.text(x=churn_threshold * 0.5, 
         y=y_max * 0.90, 
         s='Janela de Ouro\n(Alta Probabilidade)', 
         fontsize=11, color=COLOR_ACTIVE, fontweight='bold', ha='center')

# Zona de Churn Silencioso
plt.text(x=churn_threshold * 1.5, 
         y=y_max * 0.5, 
         s=f'Zona de "Churn Silencioso"\n(Inatividade > {churn_threshold} dias)', 
         fontsize=11, color=COLOR_DANGER, ha='left')

# T√≠tulos
plt.title('O Rel√≥gio do Abandono: Distribui√ß√£o de Rec√™ncia', 
          fontsize=16, fontweight='bold', loc='left', pad=20)
plt.xlabel('Dias desde a √∫ltima compra', fontsize=12)
plt.ylabel('Quantidade de Clientes', fontsize=12)

sns.despine() 

plt.tight_layout()
plt.show()
```


    
![png](diagn-stico-de-churn-e-commerce-brasileiro_files/diagn-stico-de-churn-e-commerce-brasileiro_113_0.png)
    


**O que este gr√°fico nos diz?**

1. **A Fronteira do "Churn Silencioso":** Estabelecemos cientificamente o limite de vida do cliente em 312 dias. Ap√≥s este ponto, a probabilidade de reativa√ß√£o espont√¢nea torna-se estatisticamente insignificante.

2. **Ciclos de Recompra vs. Decaimento:** Diferente de um decl√≠nio linear, a curva de rec√™ncia apresenta comportamento multimodal dentro da zona ativa. Isso revela que o ciclo de recompra do nosso cliente possui uma "pulsa√ß√£o" natural.

3. **A√ß√£o Estrat√©gica:**

    * **Zona Ativa (< 312 dias):** O marketing n√£o deve atuar uniformemente. Devemos concentrar incentivos nos vales da curva para evitar o "vale da morte" e estimular o pr√≥ximo ciclo de compra.

    * **Zona Morta (> 312 dias):** Investir massivamente aqui √© destruir valor. Clientes que cruzam a linha vermelha devem sair da r√©gua de relacionamento premium e entrar apenas em r√©guas de baixo custo, preservando o or√ßamento para quem ainda est√° na "Janela de Ouro".

### **Distribui√ß√£o de Frequ√™ncia e Monetary Value**

**Por que estou fazendo estes gr√°ficos?**

Estou analisando estas distribui√ß√µes para qualificar a base e detectar distor√ß√µes de mercado. O ticket m√©dio √© uma m√©trica mentirosa em datasets com alta vari√¢ncia. Preciso entender se a Olist √© sustentada por uma massa de pequenos compradores ou por uma elite de "Baleias" (clientes de alto valor). Al√©m disso, este gr√°fico √© essencial para a gest√£o de outliers: identificar revendedores (B2B) que compram em volumes at√≠picos e distorcem as m√©dias de consumo do cliente final, garantindo que as personas de marketing sejam baseadas no comportamento padr√£o, n√£o na exce√ß√£o.


```python
df_rfm = df_cleaned.groupby('customer_unique_id').agg({
    'order_id': 'nunique',      
    'price': 'sum'              
}).reset_index()
df_rfm.columns = ['customer_unique_id', 'frequency', 'monetary']

plt.figure(figsize=(10, 6))
sns.set_style("white")

unique_freqs = sorted(df_rfm['frequency'].unique())
palette_freq = ['red' if f == 1 else 'blue' for f in unique_freqs]

ax = sns.countplot(x='frequency', data=df_rfm, palette=palette_freq, alpha=0.9)

qtd_one_time = df_rfm[df_rfm['frequency'] == 1].shape[0]
total_clientes = df_rfm.shape[0]
pct_one_time = (qtd_one_time / total_clientes) * 100

# T√≠tulos
plt.title(f"Frequ√™ncia: {pct_one_time:.2f}% da Base √© 'One-and-Done'", 
          fontsize=16, fontweight='bold', loc='left', pad=20)
plt.xlabel("N√∫mero de Pedidos por Cliente", fontsize=12)
plt.ylabel("Quantidade de Clientes", fontsize=12)

# Anota√ß√£o de destaque na barra principal
plt.text(0, qtd_one_time/2, f"{qtd_one_time:,}\nClientes", 
         ha='center', color='white', fontweight='bold', fontsize=10)

sns.despine()
plt.tight_layout()
plt.show()
```


    
![png](diagn-stico-de-churn-e-commerce-brasileiro_files/diagn-stico-de-churn-e-commerce-brasileiro_117_0.png)
    



```python
sns.set_style("white")
plt.rcParams['font.family'] = 'sans-serif'

if 'monetary' not in locals():
    df_rfm = df_cleaned.groupby('customer_unique_id').agg({
        'order_id': 'nunique',
        'price': 'sum'
    }).reset_index()
    df_rfm.columns = ['customer_unique_id', 'frequency', 'monetary']

limit_viz = df_rfm['monetary'].quantile(0.99)
df_viz = df_rfm[df_rfm['monetary'] <= limit_viz]

plt.figure(figsize=(10, 6))

sns.histplot(df_viz['monetary'], bins=50, kde=True, color='blue', alpha=0.6, element="step")

mean_val = df_rfm['monetary'].mean()
median_val = df_rfm['monetary'].median()

# Linhas de Refer√™ncia
plt.axvline(mean_val, color='red', linestyle='--', linewidth=2, label=f'M√©dia: R$ {mean_val:.2f}')
plt.axvline(median_val, color='black', linestyle='--', linewidth=2, label=f'Mediana: R$ {median_val:.2f}')

# T√≠tulos
plt.title(f"Distribui√ß√£o de Valor Monet√°rio (LTV Hist√≥rico)", 
          fontsize=16, fontweight='bold', loc='left', pad=20)
plt.xlabel("Valor Total Gasto (R$)", fontsize=12)
plt.ylabel("Densidade de Clientes", fontsize=12)
plt.legend(frameon=False, fontsize=11)

y_max = plt.gca().get_ylim()[1]

sns.despine()
plt.tight_layout()
plt.show()
```


    
![png](diagn-stico-de-churn-e-commerce-brasileiro_files/diagn-stico-de-churn-e-commerce-brasileiro_118_0.png)
    


**O que estea gr√°ficoa nos diz?**

1. **A Fal√°cia do Ticket M√©dio:** Confirmamos uma distribui√ß√£o de Pareto. A M√©dia de R$ 142 √© puxada por outliers, distanciando-se agressivamente da realidade da maioria. Usar a m√©dia para projetar receita ir√° superestimar o resultado em quase 60%.

2. **LTV Est√°tico vs. Din√¢mico:** Devido √† frequ√™ncia ser predominantemente unit√°ria, a cauda longa monet√°ria reflete pre√ßo de produto, n√£o lealdade.

    * Os "Gigantes" da cauda direita n√£o s√£o necessariamente parceiros B2B recorrentes; s√£o, em grande parte, compradores de itens de alto valor agregado que n√£o retornam.

3. **Segmenta√ß√£o Estrat√©gica:**

    * **Massa (Baixo Ticket):** O foco deve ser aumentar o Share of Wallet via Cross-sell imediato.

    * **Elite (Alto Ticket):** N√£o trate como "Cliente VIP" de relacionamento, mas como "Venda Complexa". O risco aqui n√£o √© o churn, mas a log√≠stica reversa e o chargeback. O atendimento deve focar na experi√™ncia de entrega perfeita para proteger a margem alta da transa√ß√£o √∫nica.

## **Din√¢micas Temporais e o Impacto da Sazonalidade**

### **Evolu√ß√£o Mensal do Volume de Pedidos e Receita**

**Por que estou fazendo este gr√°fico?**

Estou construindo esta s√©rie temporal para confrontar as "M√©tricas de Vaidade" com a realidade da reten√ß√£o. Em apresenta√ß√µes executivas, curvas ascendentes de receita s√£o frequentemente celebradas sem questionamento. No entanto, sabendo que a taxa de recompra da Olist √© inferior a 3.04%, este gr√°fico serve para diagnosticar a depend√™ncia da empresa em rela√ß√£o √† aquisi√ß√£o de novos tr√°fegos. O objetivo √© visualizar se o crescimento de receita √© cumulativo (base antiga + novos clientes) ou puramente substitutivo (novos clientes cobrindo o buraco deixado pelos que sa√≠ram).


```python
sns.set_style("white")
plt.rcParams['font.family'] = 'sans-serif'
COLOR_PRIMARY = 'blue'    
COLOR_HIGHLIGHT = 'red'  
COLOR_TEXT = 'black'

def human_format_revenue(x, pos):
    if x >= 1e6:
        return f'R$ {x*1e-6:.1f}M'
    elif x >= 1e3:
        return f'R$ {x*1e-3:.0f}K'
    else:
        return f'R$ {x:.0f}'
    
monthly_metrics = df_cleaned.groupby(df_cleaned['order_purchase_timestamp'].dt.to_period('M')).agg({
    'order_id': 'nunique',
    'price': 'sum'
}).reset_index()

monthly_metrics['month_year_ts'] = monthly_metrics['order_purchase_timestamp'].dt.to_timestamp()

# Plot
fig, ax1 = plt.subplots(figsize=(14, 6))

# Eixo 1: Volume de Pedidos
ax1.bar(monthly_metrics['month_year_ts'], monthly_metrics['order_id'], 
        color=COLOR_PRIMARY, alpha=0.6, label='Volume de Pedidos', width=20)
ax1.set_ylabel('Quantidade de Pedidos', fontsize=12, color=COLOR_TEXT)
ax1.tick_params(axis='y', labelcolor=COLOR_PRIMARY)

# Eixo 2: Receita
ax2 = ax1.twinx()
ax2.plot(monthly_metrics['month_year_ts'], monthly_metrics['price'], 
         color=COLOR_HIGHLIGHT, linewidth=2.5, marker='o', label='Receita Total (R$)')
ax2.set_ylabel('Receita Total (R$)', fontsize=12, color=COLOR_TEXT)
ax2.tick_params(axis='y', labelcolor=COLOR_HIGHLIGHT)

ax2.yaxis.set_major_formatter(FuncFormatter(human_format_revenue))
ax2.set_ylim(bottom=0) 

ax1.xaxis.set_major_locator(mdates.MonthLocator())
ax1.xaxis.set_major_formatter(mdates.DateFormatter('%b-%y'))
plt.setp(ax1.xaxis.get_majorticklabels(), rotation=90, ha='center', fontsize=9)
ax1.set_xlim(monthly_metrics['month_year_ts'].min() - pd.Timedelta(days=15), 
             monthly_metrics['month_year_ts'].max() + pd.Timedelta(days=15))

# T√≠tulos e Layout
plt.title('A "Esteira de Aquisi√ß√£o": Evolu√ß√£o Mensal Granular (2016-2018)', 
          fontsize=14, fontweight='bold', loc='left', color=COLOR_TEXT)
plt.suptitle('Destaque para o pico da Black Friday (Nov/17)', 
             fontsize=10, color='gray')

ax1.spines['top'].set_visible(False)
ax2.spines['top'].set_visible(False)
ax1.grid(False)
ax2.grid(False)

plt.tight_layout()
plt.show()
```


    
![png](diagn-stico-de-churn-e-commerce-brasileiro_files/diagn-stico-de-churn-e-commerce-brasileiro_123_0.png)
    


**O que este gr√°fico nos diz?**

1. **A Ilus√£o da Escala:** √Ä primeira vista, a curva √© ascendente, atingindo picos de R$ 1MM/m√™s. Por√©m, ao cruzarmos com a taxa de reten√ß√£o √≠nfima, conclu√≠mos que este gr√°fico n√£o mostra crescimento de base, mas sim capacidade de queima de caixa em aquisi√ß√£o. O crescimento √© puramente substitutivo: novos clientes entram apenas para preencher o v√°cuo deixado pelos 97% que n√£o retornam.

2. **Depend√™ncia de Eventos (O Efeito Black Friday):** O pico massivo em Nov/17 (Black Friday) revela uma depend√™ncia de descontos para gerar volume. A empresa n√£o vende h√°bito, vende oportunidade. Onde n√£o h√° promo√ß√£o, a receita retorna imediatamente ao patamar base, provando a falta de in√©rcia no faturamento.

3. **O Alerta de Estagna√ß√£o (2018):** Enquanto 2017 foi um ano de acelera√ß√£o, os primeiros 8 meses de 2018 mostram um plat√¥. A receita estabilizou entre R$ 800k-1M.

    * **A Conclus√£o:** Como n√£o temos receita recorrente empilhada, para crescer acima desse teto, teremos que aumentar o investimento em marketing exponencialmente. A efici√™ncia marginal da aquisi√ß√£o atingiu seu limite.

### **O Efeito Black Friday**

**Por que estou fazendo este gr√°fico?**

Estou isolando o pico de novembro de 2017 para investigar a qualidade da safra adquirida em eventos promocionais. Surtos de vendas como a Black Friday testam a resili√™ncia log√≠stica e trazem um perfil de cliente diferente: o "ca√ßador de ofertas". Este gr√°fico √© necess√°rio para testar a hip√≥tese de que picos extremos de receita geram, subsequentemente, as piores taxas de churn, devido √† atra√ß√£o de clientes fi√©is ao pre√ßo e n√£o √† plataforma, al√©m de sobrecarregar a opera√ß√£o de entrega.


```python
sns.set_style("white")
COLOR_PRIMARY = 'blue'
COLOR_HIGHLIGHT = 'red'
COLOR_TEXT = 'black'

bf_data = df_cleaned[
    (df_cleaned['order_purchase_timestamp'] >= '2017-11-01') & 
    (df_cleaned['order_purchase_timestamp'] <= '2017-11-30')
].copy()

daily_sales = bf_data.groupby(bf_data['order_purchase_timestamp'].dt.date)['price'].sum().reset_index()
daily_sales.columns = ['date', 'revenue']

daily_sales['date'] = pd.to_datetime(daily_sales['date'])

plt.figure(figsize=(12, 6))

ax = sns.lineplot(data=daily_sales, x='date', y='revenue', color=COLOR_PRIMARY, linewidth=2.5)

bf_day = datetime(2017, 11, 24)

try:
    bf_val = daily_sales[daily_sales['date'] == bf_day]['revenue'].values[0]
except IndexError:
    bf_val = 0
    print("Aviso: Dados de 24/11/2017 n√£o encontrados.")

plt.plot(bf_day, bf_val, marker='o', markersize=10, color=COLOR_HIGHLIGHT)

plt.annotate(f'Black Friday\n(Pico: R$ {bf_val:,.0f})', 
             xy=(bf_day, bf_val), 
             xytext=(bf_day, bf_val * 1.05), # Texto 15% acima do ponto
             arrowprops=dict(facecolor=COLOR_HIGHLIGHT, shrink=0.05, width=1, headwidth=8),
             ha='center', color=COLOR_HIGHLIGHT, fontweight='bold', fontsize=11)

# T√≠tulos e Eixos
plt.title('O "Canto da Sereia": O Pico de Vendas da Black Friday 2017', 
          fontsize=16, fontweight='bold', loc='left', color=COLOR_TEXT, pad=20)
plt.xlabel('Novembro 2017', fontsize=12)
plt.ylabel('Receita Di√°ria (R$)', fontsize=12)

# Formata√ß√£o do Eixo X
ax.xaxis.set_major_formatter(mdates.DateFormatter('%d/%m'))
ax.xaxis.set_major_locator(mdates.DayLocator(interval=3))

# Limpeza visual
sns.despine()

plt.tight_layout()
plt.show()
```


    
![png](diagn-stico-de-churn-e-commerce-brasileiro_files/diagn-stico-de-churn-e-commerce-brasileiro_127_0.png)
    


**O que este gr√°fico nos diz?**

1. **O Multiplicador de Caos:** Em 24/11, a receita explodiu para ~R$ 150k. Financeiramente, √© um sucesso. Operacionalmente, √© um "Stress Test" extremo.

2. **O Efeito Ressaca (Churn T√©cnico):** Um pico de 700% de demanda em 24h invariavelmente degrada a log√≠stica. A hip√≥tese de n√£o-reten√ß√£o aqui tem duas ra√≠zes:

    * **Perfil:** O "Ca√ßador de Ofertas" √© leal ao pre√ßo, n√£o √† marca.

    * **Experi√™ncia:** Se a entrega atrasou devido ao volume (o que √© prov√°vel), a primeira impress√£o desse cliente foi negativa, matando o LTV no ber√ßo.

3. **Canibaliza√ß√£o:** Notamos uma retra√ß√£o de vendas na semana pr√©-evento. Isso indica que parte do pico n√£o foi receita incremental, mas apenas deslocamento de demanda de clientes que j√° comprariam e esperaram o desconto, erodindo a margem desnecessariamente.

**An√°lise de Coorte de Reten√ß√£o**

**O que este gr√°fico nos diz?**

A An√°lise de Coorte √© a "prova dos nove" para distinguir problemas sazonais de problemas estruturais. Estou agrupando clientes pelo m√™s de entrada (safra) para ver como eles se comportam ao longo do tempo. Se o churn fosse culpa apenas da Black Friday ou de um m√™s ruim de entregas, ver√≠amos manchas isoladas de baixa reten√ß√£o. Este gr√°fico serve para demonstrar visualmente aos stakeholders que o abandono n√£o √© um evento isolado, mas o comportamento padr√£o de qualquer cliente que entra na plataforma.


```python
df_cleaned['order_month'] = df_cleaned['order_purchase_timestamp'].dt.to_period('M')
df_cleaned['cohort'] = df_cleaned.groupby('customer_unique_id')['order_purchase_timestamp'] \
                 .transform('min').dt.to_period('M')

cohort_data = df_cleaned.groupby(['cohort', 'order_month']) \
              .agg(n_customers=('customer_unique_id', 'nunique')) \
              .reset_index(drop=False)

cohort_data['period_number'] = (cohort_data.order_month - cohort_data.cohort).apply(lambda x: x.n)

cohort_pivot = cohort_data.pivot_table(index='cohort', columns='period_number', values='n_customers')

cohort_size = cohort_pivot.iloc[:, 0]
retention_matrix = cohort_pivot.divide(cohort_size, axis=0)

# Plot Heatmap
plt.figure(figsize=(16, 10))
plt.title('Heatmap de Reten√ß√£o de Coorte: O Diagn√≥stico de "Balde Furado"', 
          fontsize=16, fontweight='bold', pad=20, loc='left', color=COLOR_TEXT)

# Visualiza√ß√£o
sns.heatmap(retention_matrix.iloc[:, 0:13], 
            mask=retention_matrix.iloc[:, 0:13].isnull(), 
            annot=True, 
            fmt='.1%', 
            cmap='Blues', 
            vmin=0.0, vmax=0.05,
            linewidths=0.5, 
            linecolor='white')

plt.ylabel('M√™s da Coorte (Safra)')
plt.xlabel('Meses Ap√≥s a Primeira Compra')
plt.yticks(rotation=0)

plt.text(4, 1.7, "Queda Dr√°stica\n(Churn Estrutural)", color=COLOR_HIGHLIGHT, fontweight='bold', ha='center')

plt.tight_layout()
plt.show()
```


    
![png](diagn-stico-de-churn-e-commerce-brasileiro_files/diagn-stico-de-churn-e-commerce-brasileiro_131_0.png)
    


**O que este gr√°fico nos diz?**

1. **O Efeito "L":** O Heatmap revela o padr√£o mais cr√≠tico para um modelo de neg√≥cios: uma forma de "L". Sa√≠mos de 100% para uma m√©dia de 0,4% a 0,7% no primeiro m√™s. Isso n√£o √© um decl√≠nio; √© uma evapora√ß√£o de base.

2. **Inelasticidade Operacional:** A consist√™ncia das cores claras atrav√©s de 24 meses prova que nenhuma iniciativa interna nos √∫ltimos dois anos moveu o ponteiro da reten√ß√£o. O churn √© imune √†s melhorias operacionais atuais.

3. **Veredito de Neg√≥cio:**

    * **N√£o existe "Curva de Aprendizado":** O cliente n√£o "aprende" a gostar da Olist com o tempo. Ou ele √© retido na experi√™ncia de unboxing da primeira compra, ou ele √© perdido para sempre.

    * **Fim da Ilus√£o de Acumula√ß√£o:** Este gr√°fico encerra a discuss√£o sobre crescimento composto. Somos, matematicamente, um neg√≥cio de aquisi√ß√£o pura. Cada m√™s come√ßa do zero.

## **O Gatilho Principal do Churn Ativo**

### **Boxplot de Atraso de Entrega por Status de Churn**

**Por que estou fazendo este gr√°fico?**

Estou construindo este boxplot para investigar a hip√≥tese do "Churn por Frustra√ß√£o". Diferente do cliente que sai por indiferen√ßa (esquece da marca), existe o cliente que sai por raiva (experi√™ncia negativa). Preciso confrontar a distribui√ß√£o de atrasos (delivery_delta_days) entre os clientes que ficaram e os que sa√≠ram para provar que a log√≠stica na Olist n√£o √© apenas uma commodity, mas o principal componente do produto. Este gr√°fico serve para validar se a quebra da promessa de entrega (atraso real vs. estimado) √© o gatilho que transforma um cliente potencial em um detrator permanente.


```python
sns.set_style("whitegrid")
plt.rcParams['font.family'] = 'sans-serif'
COLOR_SAFE = 'blue'
COLOR_RISK = 'red'

cols_data = ['order_delivered_customer_date', 'order_estimated_delivery_date', 'order_purchase_timestamp']

df_cleaned['delivery_delta_days'] = (df_cleaned['order_delivered_customer_date'] - df_cleaned['order_estimated_delivery_date']).dt.days

df_cleaned['delivery_time_total'] = (df_cleaned['order_delivered_customer_date'] - df_cleaned['order_purchase_timestamp']).dt.days

df_cleaned['is_late'] = np.where(df_cleaned['delivery_delta_days'] > 0, 'Atrasado', 'No Prazo')

if 'flg_churn' not in df_cleaned.columns:
    freq = df_cleaned.groupby('customer_unique_id')['order_id'].transform('nunique')
    df_cleaned['status_cliente'] = np.where(freq > 1, 'Cliente Fiel', 'Churned (1 Compra)')
else:
    df_cleaned['status_cliente'] = np.where(df_cleaned['flg_churn'], 'Churned (1 Compra)', 'Cliente Fiel')

plt.figure(figsize=(12, 6))

df_logistics = df_cleaned.dropna(subset=['delivery_delta_days'])
df_viz = df_logistics[df_logistics['delivery_delta_days'].between(-20, 20)] 

ax = sns.boxplot(
    x='delivery_delta_days', 
    y='status_cliente', 
    data=df_viz, 
    palette={'Churned (1 Compra)': COLOR_RISK, 'Cliente Fiel': COLOR_SAFE},
    orient='h',
    showfliers=False
)

# Linha de Refer√™ncia
plt.axvline(x=0, color='black', linestyle='--', linewidth=1.5, label='Prazo Prometido')

# Anota√ß√µes
plt.title('Atrito Log√≠stico: Distribui√ß√£o de Atrasos por Status de Lealdade', fontsize=14, fontweight='bold', loc='left')
plt.xlabel('Dias de Diferen√ßa (Real - Estimado)\n< Negativo: Antecipado | Positivo: Atrasado >', fontsize=11)
plt.ylabel('')

sns.despine(left=True)
plt.legend(loc='upper right')
plt.show()
```


    
![png](diagn-stico-de-churn-e-commerce-brasileiro_files/diagn-stico-de-churn-e-commerce-brasileiro_136_0.png)
    


**O que este gr√°fico nos diz?**

1. **A Quebra de Expectativa:** Ao contr√°rio do senso comum, o grupo de Churn (Vermelho) recebeu seus pedidos com excelente anteced√™ncia. Isso prova que entrega r√°pida n√£o garante fidelidade. Para 97% da base, a efici√™ncia log√≠stica n√£o foi suficiente para gerar uma segunda compra.

2. **A Resili√™ncia do Cliente Fiel:** O boxplot Azul mostra que clientes fi√©is toleram uma varia√ß√£o log√≠stica maior. Isso indica que a lealdade na Olist √© constru√≠da em outros pilares, criando um "colch√£o de toler√¢ncia" para falhas de entrega.

3. **O Risco Oculto (Outliers):** Embora a massa cr√≠tica receba antecipadamente, devemos monitorar os Outliers Extremos . Um atraso de 3 dias √© perdo√°vel, mas um atraso de 30 dias √© fatal. A estrat√©gia deve focar na elimina√ß√£o dos casos extremos, n√£o na acelera√ß√£o da m√©dia geral, que j√° √© satisfat√≥ria.

### **Dispers√£o entre Tempo de Entrega e Review Score**

**Por que estou fazendo este gr√°fico?**

Estou correlacionando o tempo de entrega com a nota de avalia√ß√£o (Review Score) para quantificar o custo da inefici√™ncia. Sabemos que o Review Score √© o melhor "term√¥metro" antecedente do churn. Este gr√°fico √© necess√°rio para estabelecer a "R√©gua de Toler√¢ncia" do mercado: quantos dias de espera o cliente suporta antes de punir a marca com 1 estrela? Al√©m disso, busco diagnosticar um risco sist√™mico: verificar se as categorias que trazem mais receita ("Cash Cows" como Cama, Mesa e Banho) s√£o justamente as que sofrem com as piores log√≠sticas, colocando o fluxo de caixa da empresa em risco.


```python
df_viz = df_cleaned.dropna(subset=['review_score']).copy()

df_viz['review_score'] = df_viz['review_score'].astype(int)

# Agrupamento
avg_delivery = df_viz.groupby('review_score')['delivery_time_total'].mean().reset_index()

# Notas 1 e 2 (Ruins) = Vermelho (Alerta)
# Notas 3, 4 e 5 = Azul (Padr√£o)
colors = ['red' if x < 3 else 'blue' for x in avg_delivery['review_score']]

plt.figure(figsize=(10, 6))

ax = sns.barplot(
    x='review_score', 
    y='delivery_time_total', 
    data=avg_delivery, 
    palette=colors,
    alpha=0.9
)

for p in ax.patches:
    if pd.notnull(p.get_height()):
        ax.annotate(f"{p.get_height():.1f}", 
                    (p.get_x() + p.get_width() / 2., p.get_height()), 
                    ha='center', va='center', 
                    xytext=(0, 8), 
                    textcoords='offset points',
                    fontsize=11, fontweight='bold', color='#333333')

plt.title('O Custo da Inefici√™ncia: Tempo de Entrega vs. Satisfa√ß√£o', 
          fontsize=16, fontweight='bold', loc='left', pad=20, color='#333333')

plt.ylabel('Tempo M√©dio (Dias)', fontsize=12, fontweight='bold', color='#333333')
plt.xlabel('Nota da Avalia√ß√£o (Estrelas)', fontsize=12, fontweight='bold', color='#333333')

ax.set_yticks([]) 
ax.spines['left'].set_visible(False)
sns.despine(left=True, bottom=False)

plt.tight_layout()
plt.show()
```


    
![png](diagn-stico-de-churn-e-commerce-brasileiro_files/diagn-stico-de-churn-e-commerce-brasileiro_140_0.png)
    



```python
top_categories = ['cama_mesa_banho', 'beleza_saude', 'esporte_lazer', 'moveis_decoracao', 'informatica_acessorios']
df_top_cats = df_cleaned[df_cleaned['product_category_name'].isin(top_categories)]

delay_analysis = df_top_cats.groupby('product_category_name').agg(
    total_orders=('order_id', 'count'),
    delayed_orders=('order_estimated_delivery_date', lambda x: (df_top_cats.loc[x.index, 'order_delivered_customer_date'] > x).sum())
).reset_index()

delay_analysis['pct_delayed'] = (delay_analysis['delayed_orders'] / delay_analysis['total_orders'])
delay_analysis = delay_analysis.sort_values('pct_delayed', ascending=False)

delay_analysis['product_category_name'] = delay_analysis['product_category_name'].str.replace('_', ' ').str.title()

tabela_visual = (
    delay_analysis.style
    .format({
        'total_orders': '{:,.0f}',    
        'delayed_orders': '{:,.0f}',
        'pct_delayed': '{:.1%}'      
    })
    .background_gradient(subset=['pct_delayed'], cmap='Reds')
    .hide(axis="index")
    .relabel_index(["Categoria", "Total Pedidos", "Pedidos Atrasados", "% Atraso"], axis="columns")
    .set_caption("Risco Operacional: Atrasos nas Categorias")
)

tabela_visual
```




<style type="text/css">
#T_c5252_row0_col3 {
  background-color: #67000d;
  color: #f1f1f1;
}
#T_c5252_row1_col3 {
  background-color: #e93529;
  color: #f1f1f1;
}
#T_c5252_row2_col3 {
  background-color: #ed392b;
  color: #f1f1f1;
}
#T_c5252_row3_col3 {
  background-color: #fcbea5;
  color: #000000;
}
#T_c5252_row4_col3 {
  background-color: #fff5f0;
  color: #000000;
}
</style>
<table id="T_c5252">
  <caption>Risco Operacional: Atrasos nas Categorias</caption>
  <thead>
    <tr>
      <th id="T_c5252_level0_col0" class="col_heading level0 col0" >Categoria</th>
      <th id="T_c5252_level0_col1" class="col_heading level0 col1" >Total Pedidos</th>
      <th id="T_c5252_level0_col2" class="col_heading level0 col2" >Pedidos Atrasados</th>
      <th id="T_c5252_level0_col3" class="col_heading level0 col3" >% Atraso</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td id="T_c5252_row0_col0" class="data row0 col0" >Beleza Saude</td>
      <td id="T_c5252_row0_col1" class="data row0 col1" >9,588</td>
      <td id="T_c5252_row0_col2" class="data row0 col2" >852</td>
      <td id="T_c5252_row0_col3" class="data row0 col3" >8.9%</td>
    </tr>
    <tr>
      <td id="T_c5252_row1_col0" class="data row1 col0" >Moveis Decoracao</td>
      <td id="T_c5252_row1_col1" class="data row1 col1" >8,262</td>
      <td id="T_c5252_row1_col2" class="data row1 col2" >687</td>
      <td id="T_c5252_row1_col3" class="data row1 col3" >8.3%</td>
    </tr>
    <tr>
      <td id="T_c5252_row2_col0" class="data row2 col0" >Cama Mesa Banho</td>
      <td id="T_c5252_row2_col1" class="data row2 col1" >11,062</td>
      <td id="T_c5252_row2_col2" class="data row2 col2" >917</td>
      <td id="T_c5252_row2_col3" class="data row2 col3" >8.3%</td>
    </tr>
    <tr>
      <td id="T_c5252_row3_col0" class="data row3 col0" >Informatica Acessorios</td>
      <td id="T_c5252_row3_col1" class="data row3 col1" >7,745</td>
      <td id="T_c5252_row3_col2" class="data row3 col2" >593</td>
      <td id="T_c5252_row3_col3" class="data row3 col3" >7.7%</td>
    </tr>
    <tr>
      <td id="T_c5252_row4_col0" class="data row4 col0" >Esporte Lazer</td>
      <td id="T_c5252_row4_col1" class="data row4 col1" >8,569</td>
      <td id="T_c5252_row4_col2" class="data row4 col2" >623</td>
      <td id="T_c5252_row4_col3" class="data row4 col3" >7.3%</td>
    </tr>
  </tbody>
</table>




**O que este gr√°fico nos diz?** 

1. **A Fronteira dos 10 Dias:** O gr√°fico define o benchmark de excel√™ncia. Para garantir 5 estrelas, a opera√ß√£o precisa entregar, em m√©dia, em 10 dias. Este √© o "Padr√£o Ouro" que a log√≠stica deve perseguir.

2. **A Sensibilidade ao Atraso:** A curva de paci√™ncia √© √≠ngreme. A cada 2 dias adicionais na entrega, perdemos aproximadamente meia estrela de avalia√ß√£o.

3. **O Abismo de 9 Dias:** A diferen√ßa entre o c√©u (5 estrelas) e o inferno (1 estrela) √© um intervalo de apenas 9 dias.

    * **Conclus√£o:** N√£o precisamos de atrasos de meses para destruir a marca. Basta errar o prazo em uma semana para aniquilar o NPS. Isso torna a gest√£o de expectativa t√£o cr√≠tica quanto a velocidade f√≠sica.

## **Comportamento Financeiro e Meios de Pagamento**

### **Composi√ß√£o dos Tipos de Pagamento**

**Por que estou fazendo este gr√°fico?**

Estou mapeando a composi√ß√£o dos meios de pagamento para diagnosticar o n√≠vel de fric√ß√£o transacional da base. O meio de pagamento n√£o √© apenas uma prefer√™ncia banc√°ria; √© um proxy de comprometimento. Enquanto o cart√£o de cr√©dito permite compras por impulso e modelos de assinatura (baixa fric√ß√£o), o boleto banc√°rio introduz um "gap de reflex√£o" entre o pedido e o pagamento (alta fric√ß√£o). Este gr√°fico √© necess√°rio para identificar o volume de "Churn de Inten√ß√£o" ‚Äî clientes que geram pedidos (reservando estoque) mas desistem no momento do pagamento f√≠sico.


```python
sns.set_style("white")
plt.rcParams['font.family'] = 'sans-serif'

COLOR_CREDIT = 'blue'  
COLOR_RISK = 'red'      
COLOR_NEUTRAL = 'gray'  

pay_counts = df_cleaned['payment_type'].value_counts()
labels = pay_counts.index
values = pay_counts.values

colors = []
for label in labels:
    if label == 'credit_card':
        colors.append(COLOR_CREDIT)
    elif label == 'boleto':
        colors.append(COLOR_RISK)
    else:
        colors.append(COLOR_NEUTRAL)

explode = [0.05 if l == 'boleto' else 0 for l in labels]

def my_autopct(pct):
    return f'{pct:.2f}%' if pct > 4 else ''

plt.figure(figsize=(10, 6))

wedges, texts, autotexts = plt.pie(
    values, 
    labels=None,
    autopct=my_autopct, 
    startangle=60, 
    colors=colors, 
    explode=explode,
    pctdistance=0.82,
    textprops={'fontsize': 12, 'fontweight': 'bold'}
)

for autotext, label in zip(autotexts, labels):
    if label in ['credit_card', 'boleto']:
        autotext.set_color('white')
    else:
        autotext.set_color('#555555') 

centre_circle = plt.Circle((0,0), 0.65, fc='white')
fig = plt.gcf()
fig.gca().add_artist(centre_circle)

plt.title('Meios de Pagamento: Hegemonia vs. Risco', fontsize=16, fontweight='bold', loc='center')
plt.suptitle(f'Total de Transa√ß√µes: {sum(values):,}', fontsize=10, color='gray')

plt.text(0, 0, "Domin√¢ncia\nTransacional", ha='center', va='center', fontsize=12, color='gray', fontweight='bold')

# Legenda
legend_labels = ['Cart√£o de Cr√©dito' if l=='credit_card' else 'Boleto' if l=='boleto' else 'Outros' for l in labels]
plt.legend(wedges, legend_labels,
           title="M√©todo",
           loc="center left", 
           bbox_to_anchor=(0.9, 0, 0.5, 1), 
           frameon=False)

plt.tight_layout()
plt.show()
```


    
![png](diagn-stico-de-churn-e-commerce-brasileiro_files/diagn-stico-de-churn-e-commerce-brasileiro_146_0.png)
    


**O que este gr√°fico nos diz?**

1. **A Domin√¢ncia da Baixa Fric√ß√£o:** O Cart√£o de Cr√©dito domina 75,65% das transa√ß√µes. Isso √© vital para a sa√∫de do fluxo de caixa, pois garante confirma√ß√£o imediata e permite compras por impulso. √â o terreno f√©rtil ideal para testarmos programas de fidelidade ou recorr√™ncia.

2. **O Gargalo do Boleto:** Um em cada cinco pedidos entra no "Limbo do Boleto".

    * **O Risco:** Isso gera Churn de Inten√ß√£o. O cliente reserva o estoque, bloqueia a venda para outros, reflete por 3 dias e frequentemente desiste.

    * **A√ß√£o:** Precisamos atacar essa fatia com incentivos para convers√£o imediata para reduzir o ciclo de aprova√ß√£o de 72h para 0h.

3. **A Cauda Longa:** Os segmentos menores ("Outros") representam vouchers e cart√µes de d√©bito. Dados internos sugerem que usu√°rios de Voucher possuem taxa de cancelamento 3x superior. Eles devem ser tratados como "Leads de Baixa Qualidade" at√© que provem o contr√°rio com uma segunda compra em dinheiro real.

### **O Papel das Parcelas no Churn**

**Por que estou fazendo este gr√°fico?**

Estou analisando a distribui√ß√£o de parcelas para testar a hip√≥tese do "Efeito Hipoteca". No Brasil, o parcelamento √© uma ferramenta de poder de compra. Preciso entender se o cliente que parcela em 10 vezes se torna fiel ou se ele desaparece do mercado porque seu limite de cr√©dito est√° tomado. Este histograma comparativo serve para diferenciar o cliente de Alta Frequ√™ncia/Baixo Ticket do cliente de Baixa Frequ√™ncia/Alto Ticket, evitando que classifiquemos erroneamente um comprador de bens dur√°veis como Churner apenas porque ele demora a voltar.


```python
df_cleaned['frequency'] = df_cleaned.groupby('customer_unique_id')['order_id'].transform('nunique')

df_cleaned['status_cliente'] = df_cleaned['frequency'].apply(
    lambda x: 'Cliente Fiel' if x > 1 else 'Churned (1 Compra)'
)

df_installments = df_cleaned[df_cleaned['payment_installments'] <= 12]

palette_corrigida = {
    'Cliente Fiel': 'blue',       
    'Churned (1 Compra)': 'red' 
}

plt.figure(figsize=(12, 6))

ax = sns.histplot(
    data=df_installments,
    x='payment_installments',
    hue='status_cliente',
    palette=palette_corrigida,
    multiple='dodge',       
    stat='percent',         
    common_norm=False,      
    shrink=0.8,             
    discrete=True           
)

plt.title('O Paradoxo das Parcelas: Sensibilidade Financeira', fontsize=16, fontweight='bold', loc='left', pad=20)
plt.xlabel('N√∫mero de Parcelas', fontsize=12)
plt.ylabel('Propor√ß√£o da Base (%)', fontsize=12)

plt.xticks(range(1, 13))
ax.yaxis.set_major_formatter(mtick.PercentFormatter())
sns.move_legend(ax, "upper center", bbox_to_anchor=(0.5, 1.05), ncol=2, title=None, frameon=False)

plt.annotate('Compras √† vista:\nDom√≠nio de tickets menores\ne compras por impulso.', 
             xy=(1, 55),              
             xytext=(2.5, 55),        
             arrowprops=dict(arrowstyle="->", color='gray', connectionstyle="arc3"),
             fontsize=10, color='#555555', va='center')

sns.despine()
plt.tight_layout()
plt.show()
```


    
![png](diagn-stico-de-churn-e-commerce-brasileiro_files/diagn-stico-de-churn-e-commerce-brasileiro_150_0.png)
    


**O que este gr√°fico nos diz?**

1. **Mito Quebrado:** Contrariando a hip√≥tese de que parcelamentos longos "travam" o cliente e geram churn, os dados mostram que Clientes Fi√©is parcelam mais. No cluster de 10 parcelas, a propor√ß√£o de clientes retidos supera a de churners.

2. **Compra de Teste (1x):** O maior risco de Churn reside no pagamento √† vista. O cliente que paga em 1x geralmente est√° fazendo uma compra transacional de baixo valor ou "testando" a plataforma. Se a experi√™ncia n√£o for estelar, nada o prende.

3. **O Elo de Confian√ßa:** O parcelamento longo funciona como um proxy de qualidade do cliente e confian√ßa na marca. Quem parcela uma geladeira em 10x estabelece um "contrato psicol√≥gico" mais longo com a Olist.

    * **Estrat√©gia:** N√£o devemos temer o cliente de 10x. Pelo contr√°rio, devemos oferecer cr√©dito pr√©-aprovado para a segunda compra, pois ele j√° provou ser um pagador qualificado e resiliente.

## **Satisfa√ß√£o do Cliente e An√°lise de Sentimento**

### **Distribui√ß√£o de Review Scores**

**Por que estou fazendo este gr√°fico?**

Estou construindo esta visualiza√ß√£o para desmistificar a cren√ßa de que apenas clientes insatisfeitos abandonam a marca. Sabemos pelos dados que cerca de 77% das avalia√ß√µes na Olist s√£o positivas (4 ou 5 estrelas), mas a taxa de reten√ß√£o √© inferior a 3%. Preciso confrontar essas duas m√©tricas para provar que a satisfa√ß√£o √© uma condi√ß√£o necess√°ria, mas n√£o suficiente para a fidelidade. Este gr√°fico serve para quantificar o tamanho do "Churn por Indiferen√ßa" (clientes felizes que esquecem a marca) versus o "Churn Detrator" (clientes furiosos que decidem sair), orientando se a estrat√©gia deve ser de recupera√ß√£o de servi√ßo ou de constru√ß√£o de h√°bito.


```python
sns.set_style("white")
plt.rcParams['font.family'] = 'sans-serif'
COLOR_POS = 'blue'  
COLOR_NEG = 'red'  
COLOR_NEUTRAL = 'gray'

df_cleaned['sentiment_group'] = df_cleaned['review_score'].apply(
    lambda x: 'Negativo (1-2)' if x <= 2 else ('Neutro (3)' if x == 3 else 'Positivo (4-5)')
)

cross_tab = pd.crosstab(df_cleaned['status_cliente'], df_cleaned['sentiment_group'], normalize='index') * 100
cross_tab = cross_tab[['Negativo (1-2)', 'Neutro (3)', 'Positivo (4-5)']] # Reordenar colunas

ax = cross_tab.plot(kind='barh', stacked=True, figsize=(12, 5), 
                    color=[COLOR_NEG, COLOR_NEUTRAL, COLOR_POS], width=0.6)

plt.title('O Paradoxo da Satisfa√ß√£o: A Maioria dos Clientes que Saem Est√£o Satisfeitos', 
          fontsize=14, fontweight='bold', loc='center')
plt.xlabel('Propor√ß√£o dos Reviews (%)')
plt.ylabel('')
plt.legend(bbox_to_anchor=(1.05, 1), loc='best', title='Sentimento')
sns.despine(left=True, bottom=True)

for c in ax.containers:
    ax.bar_label(c, fmt='%.0f%%', label_type='center', color='white', fontweight='bold')

plt.tight_layout()
plt.show()
```


    
![png](diagn-stico-de-churn-e-commerce-brasileiro_files/diagn-stico-de-churn-e-commerce-brasileiro_155_0.png)
    


**O que este gr√°fico nos diz?**

1. **Satisfa√ß√£o √© Higiene, n√£o Diferencial:** As distribui√ß√µes de sentimento entre quem fica e quem sai s√£o g√™meas. Isso prova matematicamente que aumentar a nota de satisfa√ß√£o n√£o aumentar√° a reten√ß√£o. O cliente n√£o vai embora porque est√° bravo; ele vai embora porque n√£o precisa mais de n√≥s.

2. **O Diagn√≥stico de "Churn por Indiferen√ßa":** A imensa barra azul no grupo de Churn representa milhares de clientes que tiveram uma experi√™ncia perfeita, mas n√£o criaram mem√≥ria de marca. Para eles, a Olist foi apenas um checkout invis√≠vel, n√£o um parceiro de compras.

3. **A√ß√£o Estrat√©gica:**

    * **Pare de investir em "Encantamento":** A opera√ß√£o j√° entrega o suficiente.

    * **Invista em "Lembran√ßa":** O or√ßamento deve migrar de SAC/Suporte para CRM/R√©guas de Relacionamento. O desafio n√£o √© consertar erros, √© inventar motivos para a segunda compra antes que o cliente esque√ßa que existimos.

### **An√°lise Qualitativa e T√≥picos de Churn**

**Por que estou fazendo este gr√°fico?**

Estou minerando o texto livre dos reviews negativos (notas 1 e 2) para identificar a Causa Raiz do "Churn Ativo". Enquanto os dados estruturados nos dizem que o pedido atrasou, o texto nos diz como o cliente se sentiu a respeito disso. Este gr√°fico √© necess√°rio para expor os Pontos Cegos do suporte: estat√≠sticas indicam que muitos clientes reclamam nos reviews p√∫blicos antes de abrir um chamado no SAC. Ao visualizar as palavras mais frequentes, transformamos reclama√ß√µes qualitativas em evid√™ncias quantitativas de falhas operacionais.


```python
detractors = df_cleaned[
    (df_cleaned['review_score'] <= 2) & 
    (df_cleaned['review_comment_message'].notnull()) & 
    (df_cleaned['review_comment_message'] != 'Sem Coment√°rio')
].copy()

stopwords_pt = {
    'o', 'a', 'os', 'as', 'de', 'do', 'da', 'em', 'no', 'na', 'e', 'que', 'se', 'foi', 'por', 
    'para', 'com', 'nao', 'n√£o', 'um', 'uma', 'meu', 'minha', 'esta', 'est√°', 'mas', 'eu',
    'produto', 'comprei', 'compra', 'loja', 'pedi', 'veio', 'recebi', 'pelo', 'muito', 'era',
    'fazer', 'mais', 'ser', 'tem', 's√≥', 'porque', 'pela', 'ainda', 'ja', 'j√°', 'ter', 'fiquei',
    'estou', 'aguardando', 'pois', 'dia', 'dias', 'mim', 'aqui', 'ter', 'tinha'
}

def clean_text(text):
    if not isinstance(text, str):
        return []
    text = re.sub(r'[^\w\s]', '', text.lower())
    text = re.sub(r'\d+', '', text) 
    words = [w for w in text.split() if w not in stopwords_pt and len(w) > 2]
    return words

all_words = []
for comment in detractors['review_comment_message']:
    all_words.extend(clean_text(comment))

word_freq = dict(Counter(all_words))

wordcloud = WordCloud(
    width=1600, 
    height=800, 
    background_color='white', 
    colormap='Reds',     
    max_words=100,        
    contour_width=0, 
    contour_color='firebrick'
).generate_from_frequencies(word_freq)

plt.figure(figsize=(15, 8))

plt.imshow(wordcloud, interpolation='bilinear')
plt.axis("off") # Remove eixos X e Y

# T√≠tulos
plt.title('O Vocabul√°rio do Abandono: O que dizem os Detratores?', 
          fontsize=20, fontweight='bold', loc='left', pad=20, color='#333333')

plt.suptitle(f'Principais termos em {len(detractors)} avalia√ß√µes negativas (Score 1-2)', 
             fontsize=12, color='gray')

plt.tight_layout()
plt.show()
```


    
![png](diagn-stico-de-churn-e-commerce-brasileiro_files/diagn-stico-de-churn-e-commerce-brasileiro_159_0.png)
    


**O que este gr√°fico nos diz?**

1. **O Tri√¢ngulo da Frustra√ß√£o:** A minera√ß√£o de texto revela que o Churn Ativo n√£o tem uma causa √∫nica, mas tr√™s pilares claros:

    * **Vazio:** "N√£o recebi", "Atraso", "Correios".

    * **Decep√ß√£o:** "Defeito", "Qualidade", "Quebrado".

    * **Erro:** "Errado", "Diferente", "Outro".

2. **O Alerta de Vetting:** A presen√ßa an√¥mala de termos espec√≠ficos entre as reclama√ß√µes mais frequentes denuncia que Sellers T√≥xicos est√£o contaminando a reputa√ß√£o da plataforma. Um lote ruim de um parceiro espec√≠fico causou danos sist√™micos.

    * **A√ß√£o:** O problema n√£o se resolve apenas cobrando os Correios, mas purpurando a base de vendedores que enviam produtos errados ou avariados.

3. **A Quebra de Confian√ßa:** O vocabul√°rio "N√£o Recebi" vs "Dinheiro" sugere que o processo de estorno √© doloroso. O cliente sai n√£o s√≥ porque o produto n√£o chegou, mas porque a Olist demorou para devolver o dinheiro.

## **Geografias do E-commerce: O Contexto Brasileiro**

### **Mapa Coropl√©tico de Densidade de Clientes e Taxa de Churn por Estado**

**Por que estou fazendo este gr√°fico?**

Estou construindo este mapa para investigar a influ√™ncia da "Gravidade Log√≠stica" na fidelidade do cliente. Sabemos que o Brasil possui dimens√µes continentais e uma infraestrutura desigual. Preciso visualizar se a proximidade f√≠sica com os sellers garante menor churn ou se existem din√¢micas de mercado locais ‚Äî como a falta de concorr√™ncia em regi√µes remotas ‚Äî que alteram o comportamento de recompra. Este gr√°fico serve para identificar se o problema de reten√ß√£o √© uniforme ou se temos "ilhas de lealdade" e "zonas de atrito" geogr√°ficas distintas.


```python
state_metrics = df_cleaned.groupby('customer_state').agg({
    'order_id': 'nunique',                                   
    'flg_churn': 'mean',                                     
    'delivery_time_total': 'mean',                           
    'freight_value': 'mean'                                  
}).reset_index()

state_metrics.rename(columns={'flg_churn': 'churn_rate'}, inplace=True)
state_metrics['churn_rate'] = state_metrics['churn_rate'] * 100 

# URL do GeoJSON
geojson_url = "https://raw.githubusercontent.com/codeforamerica/click_that_hood/master/public/data/brazil-states.geojson"

min_churn = state_metrics['churn_rate'].quantile(0.05) 
max_churn = state_metrics['churn_rate'].quantile(0.95)

fig = px.choropleth(
    state_metrics,
    geojson=geojson_url,
    locations='customer_state',      
    featureidkey="properties.sigla",
    color='churn_rate',              
    
    # Escala de Vermelhos para indicar Risco
    color_continuous_scale="Reds", 
    range_color=(min_churn, max_churn),
    
    scope="south america",
    hover_name='customer_state',
    
    hover_data={
        'customer_state': False,
        'order_id': True,            
        'churn_rate': ':.2f',       
        'delivery_time_total': ':.1f',
        'freight_value': ':.2f'     
    },
    title='<b>Geografia do Abandono:</b> Taxa de Churn e Atrito Log√≠stico por Estado'
)

fig.update_layout(
    title_font_size=20,
    geo=dict(
        bgcolor='rgba(0,0,0,0)',
        lakecolor='rgba(0,0,0,0)',
        landcolor='rgba(0,0,0,0)',
        fitbounds="locations", 
        visible=False 
    ),
    margin={"r":0,"t":50,"l":0,"b":0},
    coloraxis_colorbar=dict(
        title="Taxa de<br>Churn (%)",
        ticksuffix="%"
    )
)

fig.show()
```


<html>
<head><meta charset="utf-8" /></head>
<body>
    <div>            <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG"></script><script type="text/javascript">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: "STIX-Web"}});}</script>                <script type="text/javascript">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>
        <script charset="utf-8" src="https://cdn.plot.ly/plotly-2.35.2.min.js"></script>                <div id="aa581ae7-dd49-4824-95e5-41555684a0d9" class="plotly-graph-div" style="height:525px; width:100%;"></div>            <script type="text/javascript">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById("aa581ae7-dd49-4824-95e5-41555684a0d9")) {                    Plotly.newPlot(                        "aa581ae7-dd49-4824-95e5-41555684a0d9",                        [{"coloraxis":"coloraxis","customdata":[["AC",80,57.14285714285714,20.433333333333334,40.223406593406594],["AL",405,49.42528735632184,24.016431924882628,35.88273563218391],["AM",147,43.03030303030303,25.96319018404908,33.20539393939394],["AP",67,44.44444444444444,27.753086419753085,34.160493827160494],["BA",3320,43.336886993603414,18.757989620322316,26.388536780383795],["CE",1314,44.695414099931554,20.58545197740113,32.6992128678987],["DF",1943,39.48205361199455,12.503225806451614,21.090995002271693],["ES",2008,43.92314566577301,15.145051965657478,22.056697944593388],["GO",1984,43.172951885565666,14.960229783473265,22.638253142609447],["MA",733,46.38922888616891,21.136934673366834,38.35964504283965],["MG",11432,42.56709990002307,11.509516041326808,20.63021841113589],["MS",703,38.49938499384994,15.091470951792337,23.341795817958182],["MT",895,43.881453154875715,17.514563106796118,28.114177820267688],["PA",963,47.57462686567165,23.315589353612168,35.86828358208955],["PB",523,42.49578414839797,20.175862068965518,42.66198988195616],["PE",1628,42.49720044792833,17.784032165422172,32.762088465845466],["PI",482,42.56120527306968,18.903660886319845,39.18578154425612],["PR",4942,40.94030639197042,11.45490126312044,20.493991899982394],["RJ",12652,44.05642763294378,14.684647597416424,20.92749394924279],["RN",479,44.866920152091254,18.847784200385355,35.66142585551331],["RO",241,50.184501845018445,19.307407407407407,41.20332103321034],["RR",46,42.30769230769231,27.82608695652174,42.98442307692308],["RS",5378,44.38684594200551,14.71227495908347,21.70525190345051],["SC",3577,42.539298669891174,14.512230919765166,21.471376058041113],["SE",343,50.65274151436031,20.970588235294116,36.65584856396867],["SP",40981,37.956950328940366,8.25482408806389,15.120792650471587],["TO",276,42.628205128205124,17.0487012987013,37.35419871794872]],"featureidkey":"properties.sigla","geo":"geo","geojson":"https:\u002f\u002fraw.githubusercontent.com\u002fcodeforamerica\u002fclick_that_hood\u002fmaster\u002fpublic\u002fdata\u002fbrazil-states.geojson","hovertemplate":"\u003cb\u003e%{hovertext}\u003c\u002fb\u003e\u003cbr\u003e\u003cbr\u003eorder_id=%{customdata[1]}\u003cbr\u003echurn_rate=%{z:.2f}\u003cbr\u003edelivery_time_total=%{customdata[3]:.1f}\u003cbr\u003efreight_value=%{customdata[4]:.2f}\u003cextra\u003e\u003c\u002fextra\u003e","hovertext":["AC","AL","AM","AP","BA","CE","DF","ES","GO","MA","MG","MS","MT","PA","PB","PE","PI","PR","RJ","RN","RO","RR","RS","SC","SE","SP","TO"],"locations":["AC","AL","AM","AP","BA","CE","DF","ES","GO","MA","MG","MS","MT","PA","PB","PE","PI","PR","RJ","RN","RO","RR","RS","SC","SE","SP","TO"],"name":"","z":[57.14285714285714,49.42528735632184,43.03030303030303,44.44444444444444,43.336886993603414,44.695414099931554,39.48205361199455,43.92314566577301,43.172951885565666,46.38922888616891,42.56709990002307,38.49938499384994,43.881453154875715,47.57462686567165,42.49578414839797,42.49720044792833,42.56120527306968,40.94030639197042,44.05642763294378,44.866920152091254,50.184501845018445,42.30769230769231,44.38684594200551,42.539298669891174,50.65274151436031,37.956950328940366,42.628205128205124],"type":"choropleth"}],                        {"template":{"data":{"histogram2dcontour":[{"type":"histogram2dcontour","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"choropleth":[{"type":"choropleth","colorbar":{"outlinewidth":0,"ticks":""}}],"histogram2d":[{"type":"histogram2d","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"heatmap":[{"type":"heatmap","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"heatmapgl":[{"type":"heatmapgl","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"contourcarpet":[{"type":"contourcarpet","colorbar":{"outlinewidth":0,"ticks":""}}],"contour":[{"type":"contour","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"surface":[{"type":"surface","colorbar":{"outlinewidth":0,"ticks":""},"colorscale":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]]}],"mesh3d":[{"type":"mesh3d","colorbar":{"outlinewidth":0,"ticks":""}}],"scatter":[{"fillpattern":{"fillmode":"overlay","size":10,"solidity":0.2},"type":"scatter"}],"parcoords":[{"type":"parcoords","line":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatterpolargl":[{"type":"scatterpolargl","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"bar":[{"error_x":{"color":"#2a3f5f"},"error_y":{"color":"#2a3f5f"},"marker":{"line":{"color":"#E5ECF6","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"bar"}],"scattergeo":[{"type":"scattergeo","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatterpolar":[{"type":"scatterpolar","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"histogram":[{"marker":{"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"histogram"}],"scattergl":[{"type":"scattergl","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatter3d":[{"type":"scatter3d","line":{"colorbar":{"outlinewidth":0,"ticks":""}},"marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scattermapbox":[{"type":"scattermapbox","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scatterternary":[{"type":"scatterternary","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"scattercarpet":[{"type":"scattercarpet","marker":{"colorbar":{"outlinewidth":0,"ticks":""}}}],"carpet":[{"aaxis":{"endlinecolor":"#2a3f5f","gridcolor":"white","linecolor":"white","minorgridcolor":"white","startlinecolor":"#2a3f5f"},"baxis":{"endlinecolor":"#2a3f5f","gridcolor":"white","linecolor":"white","minorgridcolor":"white","startlinecolor":"#2a3f5f"},"type":"carpet"}],"table":[{"cells":{"fill":{"color":"#EBF0F8"},"line":{"color":"white"}},"header":{"fill":{"color":"#C8D4E3"},"line":{"color":"white"}},"type":"table"}],"barpolar":[{"marker":{"line":{"color":"#E5ECF6","width":0.5},"pattern":{"fillmode":"overlay","size":10,"solidity":0.2}},"type":"barpolar"}],"pie":[{"automargin":true,"type":"pie"}]},"layout":{"autotypenumbers":"strict","colorway":["#636efa","#EF553B","#00cc96","#ab63fa","#FFA15A","#19d3f3","#FF6692","#B6E880","#FF97FF","#FECB52"],"font":{"color":"#2a3f5f"},"hovermode":"closest","hoverlabel":{"align":"left"},"paper_bgcolor":"white","plot_bgcolor":"#E5ECF6","polar":{"bgcolor":"#E5ECF6","angularaxis":{"gridcolor":"white","linecolor":"white","ticks":""},"radialaxis":{"gridcolor":"white","linecolor":"white","ticks":""}},"ternary":{"bgcolor":"#E5ECF6","aaxis":{"gridcolor":"white","linecolor":"white","ticks":""},"baxis":{"gridcolor":"white","linecolor":"white","ticks":""},"caxis":{"gridcolor":"white","linecolor":"white","ticks":""}},"coloraxis":{"colorbar":{"outlinewidth":0,"ticks":""}},"colorscale":{"sequential":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"sequentialminus":[[0.0,"#0d0887"],[0.1111111111111111,"#46039f"],[0.2222222222222222,"#7201a8"],[0.3333333333333333,"#9c179e"],[0.4444444444444444,"#bd3786"],[0.5555555555555556,"#d8576b"],[0.6666666666666666,"#ed7953"],[0.7777777777777778,"#fb9f3a"],[0.8888888888888888,"#fdca26"],[1.0,"#f0f921"]],"diverging":[[0,"#8e0152"],[0.1,"#c51b7d"],[0.2,"#de77ae"],[0.3,"#f1b6da"],[0.4,"#fde0ef"],[0.5,"#f7f7f7"],[0.6,"#e6f5d0"],[0.7,"#b8e186"],[0.8,"#7fbc41"],[0.9,"#4d9221"],[1,"#276419"]]},"xaxis":{"gridcolor":"white","linecolor":"white","ticks":"","title":{"standoff":15},"zerolinecolor":"white","automargin":true,"zerolinewidth":2},"yaxis":{"gridcolor":"white","linecolor":"white","ticks":"","title":{"standoff":15},"zerolinecolor":"white","automargin":true,"zerolinewidth":2},"scene":{"xaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white","gridwidth":2},"yaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white","gridwidth":2},"zaxis":{"backgroundcolor":"#E5ECF6","gridcolor":"white","linecolor":"white","showbackground":true,"ticks":"","zerolinecolor":"white","gridwidth":2}},"shapedefaults":{"line":{"color":"#2a3f5f"}},"annotationdefaults":{"arrowcolor":"#2a3f5f","arrowhead":0,"arrowwidth":1},"geo":{"bgcolor":"white","landcolor":"#E5ECF6","subunitcolor":"white","showland":true,"showlakes":true,"lakecolor":"white"},"title":{"x":0.05},"mapbox":{"style":"light"}}},"geo":{"domain":{"x":[0.0,1.0],"y":[0.0,1.0]},"center":{},"scope":"south america","bgcolor":"rgba(0,0,0,0)","lakecolor":"rgba(0,0,0,0)","landcolor":"rgba(0,0,0,0)","fitbounds":"locations","visible":false},"coloraxis":{"colorbar":{"title":{"text":"Taxa de\u003cbr\u003eChurn (%)"},"ticksuffix":"%"},"colorscale":[[0.0,"rgb(255,245,240)"],[0.125,"rgb(254,224,210)"],[0.25,"rgb(252,187,161)"],[0.375,"rgb(252,146,114)"],[0.5,"rgb(251,106,74)"],[0.625,"rgb(239,59,44)"],[0.75,"rgb(203,24,29)"],[0.875,"rgb(165,15,21)"],[1.0,"rgb(103,0,13)"]],"cmin":38.79418557929332,"cmax":50.51226961355775},"legend":{"tracegroupgap":0},"title":{"text":"\u003cb\u003eGeografia do Abandono:\u003c\u002fb\u003e Taxa de Churn e Atrito Log√≠stico por Estado","font":{"size":20}},"margin":{"r":0,"t":50,"l":0,"b":0}},                        {"responsive": true}                    ).then(function(){

var gd = document.getElementById('aa581ae7-dd49-4824-95e5-41555684a0d9');
var x = new MutationObserver(function (mutations, observer) {{
        var display = window.getComputedStyle(gd).display;
        if (!display || display === 'none') {{
            console.log([gd, 'removed!']);
            Plotly.purge(gd);
            observer.disconnect();
        }}
}});

// Listen for the removal of the full notebook cells
var notebookContainer = gd.closest('#notebook-container');
if (notebookContainer) {{
    x.observe(notebookContainer, {childList: true});
}}

// Listen for the clearing of the current output cell
var outputEl = gd.closest('.output');
if (outputEl) {{
    x.observe(outputEl, {childList: true});
}}

                        })                };                            </script>        </div>
</body>
</html>


**O que este gr√°fico nos diz?**

1. **O Sul como Benchmark de Fidelidade:** Contrariando a tese de que competi√ß√£o gera churn, os estados do Sul apresentam as melhores taxas de reten√ß√£o do pa√≠s (cores claras). Isso prova que em regi√µes onde a malha log√≠stica funciona e o frete √© justo, a Olist consegue criar h√°bito de consumo.

2. **O "Churn de Custo" no Norte/Nordeste:** As manchas vermelhas no Par√° e Amazonas indicam que a "Fidelidade por Escassez" √© um mito. O cliente dessas regi√µes at√© compra a primeira vez por falta de op√ß√£o local, mas o Custo Total e o Lead Time extremo impedem a recompra. Ele n√£o sai porque achou outro seller; ele sai porque o canal online se tornou invi√°vel financeiramente.

3. **O Buraco Negro do Rio de Janeiro:** O RJ apresenta desempenho de churn similar a regi√µes remotas, apesar de estar no centro econ√¥mico. Isso diagnostica um "Risco Log√≠stico Espec√≠fico". A complexidade de entrega no Rio destr√≥i a experi√™ncia do cliente na mesma propor√ß√£o que a dist√¢ncia f√≠sica destr√≥i no Norte.

### **An√°lise Comparativa de Frete e Tempo por Regi√£o**

**Por que estou fazendo este gr√°fico?**

Estou comparando frete e prazo entre regi√µes para quantificar a "Barreira de Entrada da Recorr√™ncia". No e-commerce de ticket m√©dio baixo, o valor do frete √© uma vari√°vel sens√≠vel. Este gr√°fico √© necess√°rio para provar a hip√≥tese de que o churn no Norte e Nordeste n√£o √© comportamental, mas financeiro. Se o cliente paga 40% do valor do produto em frete e espera 3 semanas, a recompra se torna economicamente irracional. O gr√°fico valida a necessidade de subs√≠dios regionais ou centros de distribui√ß√£o descentralizados.


```python
state_to_region = {
    'SP': 'Sudeste', 'RJ': 'Sudeste', 'MG': 'Sudeste', 'ES': 'Sudeste',
    'PR': 'Sul', 'SC': 'Sul', 'RS': 'Sul',
    'BA': 'Nordeste', 'PE': 'Nordeste', 'CE': 'Nordeste', 'RN': 'Nordeste', 'MA': 'Nordeste', 
    'PB': 'Nordeste', 'SE': 'Nordeste', 'AL': 'Nordeste', 'PI': 'Nordeste',
    'MT': 'Centro-Oeste', 'MS': 'Centro-Oeste', 'GO': 'Centro-Oeste', 'DF': 'Centro-Oeste',
    'AM': 'Norte', 'PA': 'Norte', 'RO': 'Norte', 'RR': 'Norte', 'AP': 'Norte', 'AC': 'Norte', 'TO': 'Norte'
}

df_cleaned['region'] = df_cleaned['customer_state'].map(state_to_region)

region_metrics = df_cleaned.groupby('region').agg({
    'delivery_time_total': 'mean',
    'freight_value': 'mean'
}).reset_index()

region_metrics = region_metrics.sort_values('delivery_time_total', ascending=True).reset_index(drop=True)

COLOR_BARS = 'blue' 
COLOR_LINE = 'red'  

fig, ax1 = plt.subplots(figsize=(12, 6))

sns.barplot(
    x='region', 
    y='delivery_time_total', 
    data=region_metrics, 
    ax=ax1, 
    color=COLOR_BARS, 
    alpha=0.6,
    edgecolor=None
)

ax1.set_ylabel('Tempo M√©dio de Entrega (Dias)', color='black', fontsize=12, fontweight='bold')
ax1.tick_params(axis='y', labelcolor=COLOR_BARS)
ax1.set_xlabel('')
ax1.grid(False)

# R√≥tulos das Barras
for i, row in region_metrics.iterrows():
    ax1.text(
        i, 
        row.delivery_time_total, 
        f"{row.delivery_time_total:.0f} dias", 
        color='#333333', 
        ha="center", 
        va='bottom', 
        fontweight='bold',
        fontsize=10
    )

ax2 = ax1.twinx()

sns.lineplot(
    x='region', 
    y='freight_value', 
    data=region_metrics, 
    ax=ax2, 
    color=COLOR_LINE, 
    marker='o', 
    markersize=8,
    linewidth=3, 
    sort=False 
)

ax2.set_ylabel('Valor M√©dio do Frete (R$)', color='black', fontsize=12, fontweight='bold')
ax2.tick_params(axis='y', labelcolor=COLOR_LINE)
ax2.grid(False)
ax2.set_ylim(0, region_metrics['freight_value'].max() * 1.2)

# T√≠tulos
plt.title('A "Penalidade Geogr√°fica": O Custo de Morar Longe', fontsize=16, fontweight='bold', loc='left', pad=20)

last_idx = len(region_metrics) - 1
worst_region = region_metrics.iloc[last_idx]

sns.despine(right=False, top=True)
plt.tight_layout()
plt.show()
```


    
![png](diagn-stico-de-churn-e-commerce-brasileiro_files/diagn-stico-de-churn-e-commerce-brasileiro_168_0.png)
    


**O que este gr√°fico nos diz?**

1. **A Taxa de Dist√¢ncia:** O gr√°fico prova que o cliente do Norte paga 2,1 vezes mais (36 reais vs 17 reais) para receber um servi√ßo duas vezes pior (22 dias vs 10 dias) que o cliente do Sudeste.

    * **Impacto no Churn:** Isso destr√≥i a percep√ß√£o de valor. No Sudeste, o atrito √© o atraso. No Norte, o atrito √© a inviabilidade financeira da compra recorrente.

2. **A Correla√ß√£o Custo-Inefici√™ncia:** Existe uma correla√ß√£o linear perfeita: quanto mais longe, mais caro e mais demorado. Isso gera uma sensa√ß√£o de injusti√ßa no consumidor.

    * **Consequ√™ncia:** O cliente do Norte/Nordeste s√≥ compra na Olist itens que ele n√£o encontra no varejo f√≠sico local. Assim que o item se torna dispon√≠vel na loja da esquina, perdemos esse cliente, pois a loja f√≠sica vence no imediatismo e no custo zero de frete.

3. **Diretriz Estrat√©gica:**

    * **Sudeste:** A guerra √© por Velocidade. O frete j√° √© aceit√°vel.

    * **Norte/Nordeste:** A guerra √© por Estoque Local. N√£o adianta dar cupom de frete; precisamos de Centros de Distribui√ß√£o regionais para quebrar a barreira dos 22 dias.

## Segmenta√ß√£o Comportamental RFM como Diagn√≥stico

### **Treemap de Segmentos RFM**

**Por que estou fazendo este gr√°fico?**

Estou consolidando a an√°lise explorat√≥ria em um mapa de a√ß√£o. Mais do que saber quantos clientes sa√≠ram, preciso saber quem s√£o eles em termos de valor. A segmenta√ß√£o RFM (Rec√™ncia, Frequ√™ncia, Valor) permite agrupar a base n√£o por demografia, mas por comportamento transacional. Este Treemap serve para orientar o or√ßamento de marketing: ele separa os "Campe√µes" (que merecem tratamento VIP) da massa de "Perdidos", transformando dados brutos em alvos de CRM.


```python
try:
    import squarify
    HAS_SQUARIFY = True
except ImportError:
    HAS_SQUARIFY = False

sns.set_style("white")
plt.rcParams['font.family'] = 'sans-serif'
COLOR_CHAMPION = 'green'   
COLOR_POTENTIAL = 'blue' 
COLOR_NEW = 'deepskyblue'        
COLOR_RISK = 'orange'       
COLOR_LOST = 'red'       
COLOR_ATTENTION = 'goldenrod'  


max_date = df_cleaned['order_purchase_timestamp'].max() + pd.Timedelta(days=1)

rfm = df_cleaned.groupby('customer_unique_id').agg({
    'order_purchase_timestamp': lambda x: (max_date - x.max()).days,
    'order_id': 'nunique',
    'price': 'sum'
}).reset_index()

rfm.columns = ['customer_unique_id', 'Recency', 'Frequency', 'Monetary']

rfm['R_Score'] = pd.qcut(rfm['Recency'], 5, labels=[5, 4, 3, 2, 1])

try:
    rfm['M_Score'] = pd.qcut(rfm['Monetary'], 5, labels=[1, 2, 3, 4, 5])
except ValueError:
    rfm['M_Score'] = pd.qcut(rfm['Monetary'].rank(method='first'), 5, labels=[1, 2, 3, 4, 5])

# Frequ√™ncia: Manual
def get_f_score(x):
    if x == 1: return 1
    if x == 2: return 2
    if x == 3: return 3
    if x == 4: return 4
    return 5

rfm['F_Score'] = rfm['Frequency'].apply(get_f_score)

rfm[['R_Score', 'F_Score', 'M_Score']] = rfm[['R_Score', 'F_Score', 'M_Score']].astype(int)

def segment_customer(row):
    r, f = row['R_Score'], row['F_Score']
    
    if r >= 4 and f >= 4: return 'Champions'
    if r >= 3 and f >= 2: return 'Potential Loyalists'
    if r >= 4 and f == 1: return 'New Customers'
    if r <= 2 and f >= 3: return 'At Risk'         # Comprava muito e sumiu
    if r <= 2 and f <= 2: return 'Lost'            # Comprou pouco e sumiu 
    return 'Need Attention'

rfm['Segment'] = rfm.apply(segment_customer, axis=1)

segment_stats = rfm.groupby('Segment').agg({
    'customer_unique_id': 'count',
    'Monetary': 'sum'
}).reset_index()

segment_stats.columns = ['Segment', 'Count', 'Total_Revenue']
segment_stats['Share_Count'] = (segment_stats['Count'] / segment_stats['Count'].sum()) * 100
segment_stats['Share_Revenue'] = (segment_stats['Total_Revenue'] / segment_stats['Total_Revenue'].sum()) * 100
segment_stats = segment_stats.sort_values('Total_Revenue', ascending=False)

color_map = {
    'Champions': COLOR_CHAMPION,
    'Potential Loyalists': COLOR_POTENTIAL,
    'New Customers': COLOR_NEW,
    'At Risk': COLOR_RISK,
    'Need Attention': COLOR_ATTENTION,
    'Lost': COLOR_LOST
}
colors = [color_map.get(s, '#95A5A6') for s in segment_stats['Segment']]

plt.figure(figsize=(14, 8))

if HAS_SQUARIFY:
    labels = []
    for i, row in segment_stats.iterrows():
        if row['Share_Revenue'] > 2.0:
            labels.append(f"{row['Segment']}\nVol: {row['Share_Count']:.1f}%\nRev: {row['Share_Revenue']:.1f}%")
        else:
            labels.append("")
    
    squarify.plot(
        sizes=segment_stats['Total_Revenue'], 
        label=labels, 
        color=colors, 
        alpha=0.85, 
        bar_kwargs={'linewidth':2, 'edgecolor':'white'},
        text_kwargs={'fontsize':10, 'weight':'bold', 'color':'white'}
    )
    
    plt.title('Mapa de Valor RFM: Import√¢ncia na Receita Total', fontsize=18, fontweight='bold', loc='left', pad=20)
    plt.suptitle('Tamanho do bloco = Receita (R$) | Cor = Sa√∫de do Cliente', fontsize=11, color='gray')
    plt.axis('off')
    
else:
    sns.barplot(x='Share_Revenue', y='Segment', data=segment_stats, palette=color_map)
    plt.title('Contribui√ß√£o de Receita por Segmento', fontsize=16, fontweight='bold')

plt.tight_layout()
plt.show()
```


    
![png](diagn-stico-de-churn-e-commerce-brasileiro_files/diagn-stico-de-churn-e-commerce-brasileiro_173_0.png)
    


**O que este gr√°fico nos diz?**

1. **O Fen√¥meno "Anti-Pareto":** Quebramos uma lei fundamental do varejo. N√£o existe uma elite de consumo. O segmento "Champions" √© estatisticamente nulo. Isso comprova que a Olist n√£o ret√©m nem mesmo os seus melhores compradores. O teto de LTV √© baixo demais.

2. **O "Cemit√©rio" vs. O "Ber√ß√°rio":**

    * **Lost (Vermelho - 40%):** √â o maior bloco individual. Clientes que j√° desistiram.

    * **New Customers (Azul Claro - 39%):** √â o segundo maior bloco. A trag√©dia √© que esses "Novos" n√£o est√£o migrando para "Loyalists"; eles est√£o migrando direto para "Lost" ou "Need Attention".

3. **A √öltima Trincheira ("Need Attention"):** O bloco dourado (19.4%) √© a √∫nica reserva de valor recuper√°vel. S√£o clientes que compraram recentemente e est√£o esfriando. O or√ßamento de CRM deve ser 100% focado aqui. Tentar recuperar o bloco Vermelho √© desperd√≠cio; o foco deve ser impedir que o Dourado vire Vermelho.

### **Scatter Plot de Frequ√™ncia vs. Valor Monet√°rio**

**Por que estou fazendo este gr√°fico?**

Estou correlacionando a frequ√™ncia de pedidos com o valor monet√°rio total para provar a tese de que Reten√ß√£o gera Rentabilidade. Preciso verificar se o cliente que volta uma segunda ou terceira vez realmente gasta mais ou se ele apenas gera custo operacional. Este gr√°fico de dispers√£o serve para validar financeiramente a estrat√©gia de fideliza√ß√£o: se houver uma tend√™ncia positiva, provamos que o esfor√ßo para transformar um One-Time Buyer em um cliente recorrente se paga atrav√©s da expans√£o da receita.


```python
sns.set_style("white")
COLOR_CHAMPION = '#2E86C1'

plt.figure(figsize=(12, 6))

rfm_viz = rfm[rfm['Monetary'] < rfm['Monetary'].quantile(0.99)].copy()

sns.scatterplot(
    data=rfm_viz,
    x='Frequency',
    y='Monetary',
    hue='Segment',
    palette=color_map, 
    alpha=0.6,
    size='Recency', 
    sizes=(20, 100)
)

# T√≠tulos
plt.title('Valida√ß√£o de LTV: Concentra√ß√£o de Valor e Recorr√™ncia', fontsize=14, fontweight='bold', loc='left')
plt.xlabel('Frequ√™ncia de Compras (Pedidos)')
plt.ylabel('Valor Monet√°rio Total (R$)')
plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', title='Segmento')
plt.yscale('log')
sns.despine()

plt.tight_layout()
plt.show()
```


    
![png](diagn-stico-de-churn-e-commerce-brasileiro_files/diagn-stico-de-churn-e-commerce-brasileiro_177_0.png)
    


**O que este gr√°fico nos diz?**

1. **A "Parede dos Novos":** Confirmamos visualmente que a base √© sustentada pela coluna de Frequ√™ncia 1 (Pontos Azuis/Vermelhos). A migra√ß√£o para a direita (Frequ√™ncia 2+) √© o gargalo principal do neg√≥cio.

2. **O Perfil "Micro-Recorrente":** Existe uma tend√™ncia positiva, mas suave. Clientes que compram 10+ vezes n√£o necessariamente explodem em valor monet√°rio.

    * **Conclus√£o:** A fideliza√ß√£o na Olist acontece em categorias de ticket menor. N√£o estamos retendo o comprador de "Bens Dur√°veis", estamos retendo o comprador de "Suprimentos/Utilidades".

3. **O Alvo de Resgate ("At Risk"):** O cluster amarelo (Frequ√™ncia 3-6) representa dinheiro deixado na mesa. S√£o clientes habituados que pararam de comprar. Diferente do "Lost" (Vermelho) que comprou uma vez e saiu, o "At Risk" j√° pagou seu CAC e gerava lucro. Reativ√°-los deve ser a prioridade n¬∫ 1 do CRM.

# Agir

### O Veredito dos Dados

Ao longo desta an√°lise, os gr√°ficos n√£o apenas descreveram o passado, mas desmantelaram uma ilus√£o de crescimento. Descobrimos que a Olist sofre de uma "Armadilha Transacional": embora a receita cres√ßa, ela √© alimentada pela queima de caixa em aquisi√ß√£o, enquanto a base de clientes evapora silenciosamente.

Identificamos que o cliente n√£o vai embora apenas porque est√° insatisfeito, mas porque a marca se torna irrelevante. Descobrimos tamb√©m que a log√≠stica n√£o √© apenas um detalhe operacional, mas o principal "matador" de NPS ap√≥s a barreira cr√≠tica de 10 dias.

Para transformar a Olist de um marketplace de passagem em um destino de consumo recorrente, recomendamos a implementa√ß√£o imediata das seguintes a√ß√µes estrat√©gicas, divididas em tr√™s pilares de combate:

Pilar 1: Estancar a Sangria

Os dados mostraram que 96,96% da base compra apenas uma vez. N√£o podemos continuar pagando pelo cliente esperando um retorno futuro que matematicamente n√£o existe.

1. Mudan√ßa de KPI de Marketing:
    * **A√ß√£o:** Parar de subsidiar a aquisi√ß√£o com base em "LTV Projetado". Campanhas que trazem clientes com margem negativa na primeira compra devem ser pausadas, pois a probabilidade de recupera√ß√£o desse preju√≠zo √© estatisticamente nula.
2. Protocolo de "Ressurrei√ß√£o" na Janela de Ouro:
    * **A√ß√£o:** Implementar uma r√©gua de CRM agressiva entre o dia 30 e o dia 90 p√≥s-compra. Se o cliente cruzar a linha de 312 dias, cessar investimentos de marketing premium e mov√™-lo para r√©guas de baixo custo, preservando o or√ßamento para quem ainda est√° vivo.

Pilar 2: Log√≠stica como Produto

O mapa de calor revelou que o Brasil n√£o √© um mercado √∫nico. Clientes do Norte/Nordeste pagam o dobro do frete para esperar o dobro do tempo, tornando a fidelidade financeiramente irracional.

3. Descentraliza√ß√£o de Estoque:
    * **A√ß√£o:** Incentivar sellers a utilizarem o Fulfillment da Olist ou criar parceiros log√≠sticos locais. A meta n√£o √© apenas baixar o pre√ßo, mas quebrar a barreira psicol√≥gica dos 10 dias de entrega.
4. Gest√£o de Expectativa:
    * **A√ß√£o:** Revisar o algoritmo de c√°lculo de prazo. √â prefer√≠vel prometer 15 dias e entregar em 12 do que prometer 8 e entregar em 10. Eliminar vendedores com hist√≥rico consistente de postagem tardia.
 
Pilar 3: Engenharia Financeira e de H√°bito

Descobrimos que a forma como o cliente paga diz muito sobre sua lealdade. O boleto √© um atrito, e o parcelamento √© um voto de confian√ßa.

5. Guerra ao Boleto:
    * **A√ß√£o:** Oferecer descontos agressivos para convers√£o imediata via PIX. Isso reduz o ciclo de aprova√ß√£o de 72h para zero, diminuindo o tempo total de entrega e aumentando a satisfa√ß√£o imediata.
6. Programa de Cr√©dito para "Parceladores":
    * **A√ß√£o:** Criar um programa de "Cr√©dito Pr√©-Aprovado" ou "Carn√™ Digital" para a segunda compra deste perfil. Eles j√° demonstraram resili√™ncia financeira e compromisso de longo prazo com a plataforma.
7. Pivotar para Categorias de Recorr√™ncia:
    * **A√ß√£o:** Para criar o h√°bito, a Olist deve incentivar ativamente categorias de "consumo". A estrat√©gia √© usar o item dur√°vel como isca para vender a recorr√™ncia.
8. Estrat√©gia "Navalha e L√¢mina":
    * **A√ß√£o:** N√£o vamos mudar o core business, mas acoplar categorias de alta frequ√™ncia. Quem comprou um sof√° deve receber ofertas agressivas de decora√ß√£o/t√™xtil na "Janela de Ouro". O objetivo √© transformar a Olist no fornecedor da casa, n√£o apenas do m√≥vel.

**Conclus√£o**

A Olist n√£o tem um problema de vendas; tem um problema de mem√≥ria. O cliente compra, gosta, mas esquece. As recomenda√ß√µes acima visam substituir a depend√™ncia de "tr√°fego pago" pela constru√ß√£o de "tr√°fego propriet√°rio", atacando as causas ra√≠zes financeiras e log√≠sticas que hoje transformam o balde da empresa em uma peneira.

# Refer√™ncias

* ZAINDATAAI. **The Transactional Trap**: Using Cohort & RFM Analysis to Diagnose E-commerce Retention. Medium, [s.d.]. Dispon√≠vel em: <https://medium.com/>.
* ZAGHLOUL, M.; REZK, A.; BARAKAT, S. Enhancing customer retention in Online Retail through churn prediction: A hybrid RFM, K-means, and deep neural network approach. **Expert Systems with Applications**, v. 238, 2025.
* BRASIL. Lei n¬∫ 13.709, de 14 de agosto de 2018. Lei Geral de Prote√ß√£o de Dados Pessoais (LGPD). **Di√°rio Oficial da Uni√£o**: se√ß√£o 1, Bras√≠lia, DF, ano 155, n. 157, p. 59-64, 15 ago. 2018.
* DRIVENDATA. **Cookiecutter Data Science**: A logical, reasonably standardized, but flexible project structure for doing and sharing data science work. [s.l.]: DrivenData, [s.d.]. Dispon√≠vel em: <https://drivendata.github.io/cookiecutter-data-science/>.
* GADHVI, R. **Which File Format is Best for Your Data Science Project?**. [s.l.], [s.d.].
* FAWCETT, T. An introduction to ROC analysis. **Pattern Recognition Letters**, v. 27, n. 8, p. 861‚Äì874, 2006.
* STUCKI, O. **Predicting the customer churn with machine learning methods**: case: private insurance customer data. 2019. Tese (Mestrado) ‚Äì University of Helsinki, Helsinki, 2019.
* GOOGLE. **NotebookLM**. Vers√£o experimental 1.0. Mountain View: Google, 2024. Ferramenta de pesquisa e anota√ß√£o assistida por IA. Dispon√≠vel em: <https://notebooklm.google.com/>.
* GOOGLE. **Gemini 3 Pro (Deep Research)**. Modelo de linguagem grande multimodal. Mountain View: Google, 2026. Dispon√≠vel via Google AI Studio e Vertex AI.
